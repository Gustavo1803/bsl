[
["index.html", "Basics of Statistical Learning Start Here Caveat Emptor Who? Acknowledgements License", " Basics of Statistical Learning David Dalpiaz 2020-02-11 Start Here Welcome to Basics of Statistical Learning! What a boring title! The title was chosen to mirror the University of Illinois course STAT 432 - Basics of Statistical Learning. That title was chosen to meet certain University course naming conventions, hence the boring title. A more appropriate title would be “Machine Learning from the Perspective of a Statistician who uses R,” which is more descriptive, but still a boring title. Anyway, this “book” will often be referred to as BSL. Caveat Emptor This “book” is under active development. Literally every element of the book is subject to change, at any moment. This text, BSL, is the successor to R4SL, an unfinished work that began as a supplement to Introduction to Statistical Learning, but was never finished. (In some sense, this book is just a fresh start due to the author wanting to change the presentation of the material. The author is seriously worried that he will encounter the second-system effect.) Because this book is written with a course in mind, that is actively being taught, often out of convenience the text will speak directly to the students of that course. Thus, be aware that any reference to a “course” are a reference to STAT 432 @ UIUC. Since this book is under active development you may encounter errors ranging from typos, to broken code, to poorly explained topics. If you do, please let us know! Better yet, fix the issue yourself! If you are familiar with R Markdown and GitHub, pull requests are highly encouraged!. This process is partially automated by the edit button in the top-left corner of the html version. If your suggestion or fix becomes part of the book, you will be added to the list at the end of this chapter. We’ll also link to your GitHub account, or personal website upon request. If you’re not familiar with version control systems feel free to email the author, dalpiaz2 AT illinois DOT edu. (But also consider using this opportunity to learn a bit about version control!) See additional details in the Acknowledgements section below. While development is taking place, you may see “TODO” scattered throughout the text. These are mostly notes for internal use, but give the reader some idea of what development is still to come. For additional details on the development process, please see the README file on GitHub as well as the Issues page. Who? This book is targeted at advanced undergraduate or first year MS students in Statistics who have no prior machine learning experience. While both will be discussed in great detail, previous experience with both statistical modeling and R are assumed. In other words, this books is for students in STAT 432. Acknowledgements The following is a (likely incomplete) list of helpful contributors. This book was also influenced by the helpful contributors to R4SL. Jae-Ho Lee - STAT 432, Fall 2019 W. Jonas Reger - STAT 432, Spring 2020 Your name could be here! Please see the CONTRIBUTING document on GitHub for details on interacting with this project. Pull requests encouraged! Looking for ways to contribute? You’ll notice that a lot of the plotting code is not displayed in the text, but is available in the source. Currently that code was written to accomplish a task, but without much thought about the best way to accomplish the task. Try refactoring some of this code. Fix typos. Since the book is actively being developed, typos are getting added all the time. Suggest edits. Good feedback can be just as helpful as actually contributing code changes. License CC NC SA This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License "],
["ten-simple-rules-for-success-in-stat-432.html", "Chapter 1 Ten Simple Rules for Success in STAT 432 1.1 Rule 1: There Are No Rules 1.2 Rule 2: Read the Syllabus 1.3 Rule 3: Previous Learning is Not Gospel 1.4 Rule 4: All Statements Are True 1.5 Rule 5: Don’t Miss The Forest For The Trees 1.6 Rule 6: You Will Struggle 1.7 Rule 7: Keep It Simple 1.8 Rule 8: RTFM 1.9 Rule 9: There Are No Stupid Questions 1.10 Rule 10: Learn By Doing 1.11 Conclusion 1.12 Source", " Chapter 1 Ten Simple Rules for Success in STAT 432 STAT 432 is a difficult course. Although, as a result of the historical grade distribution I believe some students enter the course believing that it is an “easy” course. This document was written to help address the reasons for this difference between perception and reality. The style is stolen from the popular “Ten Rules” articles published in PLOS journals. A relevant example is Ten Simple Rules for Effective Statistical Practice. 1.1 Rule 1: There Are No Rules Perhaps it is odd to begin a list of rules exclaiming that there are no rules. Many students that enroll in STAT 432 have an extensive mathematics background where everything follows a set of rules. However, statistics is not mathematics. While there are certainly rules in statistics, in applied statistics, an analyst must make decisions that can only be guided by heuristics. Students often ask questions such as “What method should I use in this situation?” hoping for a specific answer. While it would be easy to simply provide an “answer” of some specific model or procedure, the reality is that the answer will almost always be “it depends” and the analyst will have to make a somewhat subjective decision based on an extremely long set of heuristics. (The other answer to “Which method should I use in this situation?” will be &quot;Who knows? Try a few and evaluate which is working best. Evaluating methods will be a big focus in the course. We care more about the ability to evaluate methods than understanding the inner workings of each method.) In other words, while we could simply write some sort of flow-chart that tells you what to do in any situation encountered in the course, we reject this authoritarian approach. We prefer to present some heuristics, some reasoning behind them, and allow you to think for yourself. Skepticism is encouraged. You are allowed to form your own opinions about the course material. Applied to the data analyses done in STAT 432: There is no single correct answer. There are only good arguments and bad arguments. 1.2 Rule 2: Read the Syllabus Please. A familiarity with the syllabus will make your experience in the course much smoother. I would suggest returning to the syllabus a number of times throughout the semester, perhaps shortly before the exams. 1.3 Rule 3: Previous Learning is Not Gospel A trap many students fall into is believing that everything they have previously learned is relevant in future courses. This is not the case. Just because a method was taught in STAT 420 or STAT 425 does not mean that it is relevant in STAT 432. The most common example of this is Variance Inflation Factors. Students seem to love to drag this concept into STAT 432. While it is certainly possible to appeal to VIFs in STAT 432, they seem to be misapplied more often than not. This is because VIFs are more relevant for inference than prediction. STAT 432 cares about prediction much more than STAT 420 and STAT 425. 1.4 Rule 4: All Statements Are True Rule 4 is somewhat related to Rule 3. The full rule would read: “All statements are true, given the correct conditions.” Rule 3 is relevant here because students will often search for information on the internet. They’ll arrive at some prescription such as “Method X is good at Task Y.” In reality, this statement is always more correctly stated as “Method X is good at Task Y under Condition Z.” In other words, context is extremely important. 1.5 Rule 5: Don’t Miss The Forest For The Trees STAT 432 covers a lot of content, sometimes at a surface level. When only scratching the surface, students find the lack of details unsatisfying. This is understandable, but realize that STAT 432 is a first course in machine learning. We don’t believe it is possible to learn all of machine learning in a single course. STAT 432 is about having an understanding of what machine learning is and what you can do with it. Our goal is not to teach you every single detail. (That is impossible.) Instead, we would like to provide a high level overview that will serve as a foundation for future learning. (Both self-study and future courses.) 1.6 Rule 6: You Will Struggle You will struggle, and that is a good thing. If everything in the course were “easy,” very little learning would take place. However, we are not advocating struggle for the sake of struggle. We want to support your “struggle” with the material. The course staff is not the enemy. The material is the “enemy.” We are here to help you. Do not hesitate to ask the course staff questions! Come to office hours! Post on Piazza! 1.7 Rule 7: Keep It Simple Please keep the KISS Principle in mind. (The name is somewhat unfortunate. No, we are not calling you stupid.) Complexity does not imply valuable. Within the context of STAT 432: All else being equal, we prefer “simple” methods and models. When writing reports, shorter is better. (As long as you convey the necessary information.) 1.8 Rule 8: RTFM Warning, the following link contains foul language: RTFM. RTFM is a common phrase in coding culture. While extremely insensitive, it is perhaps some of the most relevant advice for STAT 432. In short, if you experience a coding issue: Read the documentation of the function you are trying to use. (Anything you are doing in R involves running a function.) Search the internet (“Google”) for any error messages you’ve encountered. This should always be your first line of defense any time you encounter an issue. However, we do not expect you to be able to solve all your problems with this method! That’s why office hours exists! We simply would like you to get into this habit. Having gone through this step, you are more likely to solve the problem yourself. Additionally, you will be better prepared to discuss any issue with the course staff if you are unable to solve it yourself. 1.9 Rule 9: There Are No Stupid Questions It sounds cliche, but it is true. Do not hesitate to ask the course staff questions! Come to office hours! Post on Piazza! Do note that while there really are no stupid questions, there are some annoying questions. For example: Questions that can be answered by reading the syllabus. (“When is Exam 01?” “When are office hours?”) “Can you tell me what is wrong with my code?” The second bullet requires some explaining. The direct answer to that question is technically “Yes.” However, please note that the course staff is not a debugging machine. If you simply supply us with a bunch of code and asks us what is wrong, you’ll be met with a bit of frustration. We expect that you at least pinpoint where there is an issue with the code, within reason. (We will give some advice on how best to do this as the semester progresses.) In other words, try to ask your code question in a way that demonstrates that you have already thought about solving your issue. (See Rule #9.) We will always work with you to resolve your issue, but we ask that we are not your first attempt at a resolution. Corollary: There are no “quick” questions. Student often like to preface a question with the phrase “Just one quick question.” If you’re asking the question, how do you know how long it will take to answer? (I suppose if you know it’s in the syllabus, then the answer will be quick, but …) More often than not students ask excellent questions but then expect a short, succinct answer. When you ask a good question, this is often not possible. The point is, please come to office hours where we can have an in depth conversation, that is not time limited, with additional input from you! 1.10 Rule 10: Learn By Doing Students overvalue lecture and undervalue homework. STAT 432 will probably contain less “lecture” than you expect, and far too much “work” in the form of quizzes and analyses. Watching a lecture is a passive activity. Taking quizzes is an active activity. Reading is a passive activity. Performing an analysis is an active activity. In my opinion, students enjoy (or more specifically don’t dislike) lecture because it requires zero input from them. On the other hand, quizzes are frustrating, but that is a good thing! That frustration means that there is something to learn! Stated practically and with relevance to STAT 432: The quizzes and other course activities should be given highest priority when allotting your time. You should read all posted notes twice. The first time you should read every word of the assigned material from top to bottom. Try to understand as best as possible, but don’t spend too much time reading any particular section. In a first read, it is somewhat more important to read the material to know what is there than to fully understand it. When taking the quizzes or performing an analysis, return to the relevant section of the reading. (Because you read it once before, you’ll know a certain section exists, even if you don’t understand it.) Read it again. This time you’ll have more context, and a better chance of understanding. Run the code. Modify the code and run it again. Write some similar code from scratch by yourself. Now, return to the quiz. Recorded lectures will be sparse, but if they exist, watch it once (possibly at 2x speed) but then go back to focusing on the “active” activities. 1.11 Conclusion In summary, if you bring an open mind and a bit of effort, we believe that you will succeed in STAT 432. We don’t believe that the course is easy, but we hope that it is ultimately rewarding. 1.12 Source R Markdown: 01-ten-rules.Rmd "],
["machine-learning-overview.html", "Chapter 2 Machine Learning Overview 2.1 Reading 2.2 What is Machine Learning? 2.3 Machine Learning Tasks 2.4 Open Questions 2.5 Source", " Chapter 2 Machine Learning Overview STAT 432 is a course about machine learning? Let’s try to define machine learning. 2.1 Reading Required: ISL Chapter 1 Required: ISL Chapter 2 This chapter is dense because it is an overview of the entire book. Do not expect to completely understand this chapter during a first read. We will spend the rest of the semester elaborating on these concepts. However, seeing them at the beginning will be helpful. Recommended: Variance Explained: What’s the difference between data science, machine learning, and artificial intelligence? 2.2 What is Machine Learning? Machine learning (ML) is about learning functions from data. That’s it. Really. Pretty boring, right? To quickly address some buzzwords that come up when discussing machine learning: Deep learning is just a subset of machine learning. Artificial Intelligence (AI) overlaps machine learning but has much loftier goals. In general, if someone claims to be using AI, they are not. (They’re probably using function learning! For example, we will learn logistic regression in this course. People in marketing might call that AI! Someone who understands ML will simply call it function learning. Don’t buy the hype! We don’t need to call simple methods AI to make them effective.) Machine learning is not data science. Data science sometimes uses machine learning. Does big data exist? If it does, I would bet a lot of money that you haven’t seen it, and probably won’t see it. Analytics is just a fancy word for doing data analysis. Machine learning can be used in analyses! When it is, it is often called “Predictive Analytics.” What makes machine learning interesting are the uses of these functions. We could develop functions that have applications in a wide variety of fields. In medicine, we could develop a function that helps detect skin cancer. Input: Pixels from an image of mole Output: A probability of skin cancer In sport analytics, we could develop a function that helps determine player salary. Input: Lifetime statistics of an NBA player Output: An estimate of player’s salary In meteorology, we could develop a function to predict the weather. Input: Historic weather data in Champaign, IL Output: A probability of rain tomorrow in Champaign, IL In political science we could develop a function that predicts the mood of the president. Input: The text of a tweet from President Donald Trump Output: A prediction of Donald’s mood (happy, sad, angry, etc) In urban planning we could develop a function that predicts the rental prices of Airbnbs. Input: The attributes of the location for rent Output: An estimate of the rent of the property How do we learn these functions? By looking at many previous examples, that is, data! Again, we will learn functions from data. That’s what we’re here to do. 2.3 Machine Learning Tasks When doing machine learning, we will classify our tasks into one of two categories, supervised or unsupervised learning. (There are technically other tasks such as reinforcement learning and semi-supervised learning, but they are outside the scope of this text. To understand these advanced tasks, you should first learn the basics!) Within these two broad categories of ML tasks, we will define some specifics. 2.3.1 Supervised Learning In supervised learning, we want to “predict” a specific target, outcome, or response variable. In the following examples, this is the y variable. Supervised learning tasks are called regression if the response variable is numeric. If a supervised learning tasks has a categorical response, it is called classification. 2.3.1.1 Regression In the regression task, we want to predict numeric response variables. The predictor variables, which we will call the feature variables, or simply features can be either categorical or numeric. x1 x2 x3 y A -0.66 0.48 14.09 A 1.55 0.97 2.92 A -1.19 -0.81 15.00 A 0.15 0.28 9.29 B -1.09 -0.16 17.57 B 1.61 1.94 2.12 B 0.04 1.72 8.92 A 1.31 0.36 4.40 C 0.98 0.30 4.40 C 0.88 -0.39 4.52 With the data above, our goal would be to learn a function that takes as input values of the three features (x1, x2, and x3) and returns a prediction (best guess) for the true (but usually unknown) value of the response y. For example, we could obtain some “new” data that does not contain the response. x1 x2 x3 B -0.85 -2.41 We would then pass this data to our function, which would return a prediction of the value of y. Stated mathematically, our prediction will often be an estimate the conditional mean of \\(Y\\), given values of the \\(\\boldsymbol{X}\\) variables. \\[ \\mu(\\boldsymbol{x}) = \\mathbb{E}[Y \\mid \\boldsymbol{X} = \\boldsymbol{x}] \\] In other words, we want to learn this function, \\(\\mu(\\boldsymbol{x})\\). Much more on this later. (You can safely ignore this for now.) 2.3.1.2 Classification Classification is similar to regression, except it considers categorical response variables. x1 x2 x3 y Q 0.46 5.42 B Q 0.72 0.83 C Q 0.93 5.93 B Q 0.26 5.68 A P 0.46 0.49 B P 0.94 3.09 B P 0.98 2.34 C P 0.12 5.43 C Q 0.47 2.68 B P 0.56 5.02 B As before we want to learn a function from this data using the same inputs, except this time, we want it to output one of A, B, or C for predictions of the y variable. Again, consider some new data: x1 x2 x3 P 0.96 5.33 While ultimately we would like our function to return one of A, B, or C, what we actually would like is an intermediate return of probabilities that y is A, B, or C. In other words, we are attempting to estimate the conditional probability that \\(Y\\) is each of the possible categories, given values of the \\(\\boldsymbol{X}\\) values. \\[ p_k(\\boldsymbol{x}) = P\\left[ Y = k \\mid \\boldsymbol{X} = \\boldsymbol{x} \\right] \\] We want to learn this function, \\(p_k(\\boldsymbol{x})\\). Much more on this later. (You can safely ignore this for now.) 2.3.2 Unsupervised Learning Unsupervised learning is a very broad task that is rather difficult to define. Essentially, it is learning without a response variable. To get a better idea about what unsupervised learning is, consider some specific tasks. x1 x2 x3 x4 x5 2.74 0.46 5.42 4.43 2.28 2.81 0.72 0.83 4.87 2.61 0.86 0.93 5.93 2.33 0.22 2.49 0.26 5.68 4.11 5.84 1.93 0.46 0.49 0.02 2.59 -8.44 -9.06 -6.91 -5.00 -4.25 -7.79 -9.02 -7.66 -9.96 -4.67 -9.60 -9.88 -4.57 -8.75 -6.16 -8.03 -9.53 -7.32 -4.56 -4.17 -7.88 -9.44 -4.98 -6.33 -6.29 2.3.2.1 Clustering Clustering is essentially the task of grouping the observations of a dataset. In the above data, can you see an obvious grouping? (Hint: Compare the first five observations to the second five observations.) In general, we try to group observations that are similar. 2.3.2.2 Density Estimation Density estimation tries to do exactly what the name implies, estimate the density. In this case, the joint density of \\(X_1, X_2, X_3, X_4, X_5\\). In other words, we would like to learn the function that generated this data. (You could take the position that this is the only machine learning tasks, and all other tasks are subset of this task. We’ll hold off on explaining this for a while.) 2.3.2.3 Outlier Detection Consider some new data: x1 x2 x3 x4 x5 67 66.68 66.26 69.49 70 Was this data generated by the same process as the data above? If no, we would call it an outlier. 2.4 Open Questions The two previous sections were probably more confusing than helpful. But of course, because we haven’t started learning yet! Hopefully, you are currently pondering one very specific question: How do we learn functions from data? That’s what this text will be about! We will spend a lot of time on this question. It is what us statisticians call fitting a model. On some level the answer is: look at a bunch of old data before predicting on new data. While we will dedicate a large amount of time to answering this question, sometimes, some of the details might go unanswered. Since this is an introductory text, we can only go so far. However, as long as we answer another question, this will be OK. How do we evaluate how well learned functions work? This text places a high priority on being able to do machine learning, specifically do machine learning in R. You can actually do a lot of machine learning without fully understanding how the learning is taking place. That makes the evaluation of ML models extremely important. 2.5 Source R Markdown: 02-ml-overview.Rmd "],
["computing.html", "Chapter 3 Computing 3.1 Reading 3.2 Additional Resources 3.3 STAT 432 Idioms 3.4 Source", " Chapter 3 Computing STAT 432 is not a course about R. It is however, a course that makes heavy use of R. Because of this, you will need to be familiar with R. This text will point out some things about R along the way, but some previous study of R is necessary. 3.1 Reading The following reading suggestions are long. While it may seem daunting to read all of this material, it will likely prove to be valuable. A smart strategy would be: “Read” as much of the information here, where “read” simply means read every single word and line of code, but don’t slow down if you don’t fully understand. Return to some selections from this reading every week spending more time understanding specific sections. Whether you’re a novice or an expert, there is a high probability that any effort towards reading these sources will provide a return. If you use the strategy above, over time you will start to see the bigger picture. Required: Hands-On Programming with R - Garrett Grolemund If you have never used R or RStudio before, Part 1 (Chapters 1 - 3) will be useful. Even if you have used R before, you will likely gain something from reading these sections. Recommended: R for Data Science - Garrett Grolemund, Hadley Wickham This book helps getting you up to speed working with data in R. While it is a lot of reading, Chapters 1 - 21 may prove useful. It probably isn’t worth sitting down and reading this from start to finish right now, but reading it here and there during some free time would be a good idea. Recommended: Advanced R - Hadley Wickham Part I (Chapters 1 - 8) of this book will help create a mental model for working with R. These chapters are not an easy read, so they should be returned to often. Chapter 2 could be safely skipped for our purposes, but is important if you will use R in the long term. Reference: Applied Statistics with R - David Dalpiaz If you are a UIUC student who took the course STAT 420, the first six chapters of that book could serve as a nice refresher, however, the three readings above are preferred. Chapter 6 contain three very useful video playlists and an R Markdown template. Note that the videos were created a few years ago, thus there may be minor differences between then and now, but the general ideas are the same. Video Playlist: R and RStudio Video Playlist: Data in R Video Playlist: R Markdown Template: R Markdown R Markdown will be used throughout the course, but you will not be required to use R Markdown until the final weeks when we begin working on data analyses. At that time, we will suggest some additional reading about R Markdown. When working on quizzes until then, you can use either an R script or an R Markdown document, whichever you are more comfortable with. 3.2 Additional Resources In addition to the above readings, the following resources are more specific or more advanced, but could still prove to be useful. 3.2.1 R Efficient R programming R Programming for Data Science R Graphics Cookbook Modern Dive What They Forgot to Teach You About R The R Inferno Data Wrangling, Exploration, and Analysis with R The tidyverse Website dplyr Website readr Website tibble Website forcats Website 3.2.2 RStudio RStudio IDE Cheatsheet RStudio Resources 3.2.3 R Markdown R Markdown Cheatsheet R Markdown: The Definitive Guide - Yihui Xie, J. J. Allaire, Garrett Grolemund R Markdown Cookbook R4DS: R Markdown Chapter 3.2.3.1 Markdown Daring Fireball - Markdown: Basics GitHub - Mastering Markdown CommonMark 3.3 STAT 432 Idioms R tutorials and advice are plentiful online. While we do not want to discourage you from using the resources above, or using your own creativity, the following sections will specify some strong suggestions for how to use R, RStudio, and R Markdown in STAT 432. In other words, information below here supersedes any information from the above sources. 3.3.1 Don’t Restore Old Workspaces Due to some odd default settings in RStudio, some students never clear their R envrioment. This is a problem for a number of reasons. (It could prevent your results from being reproducible.) To get ready for STAT 432, do the following: Clear your current enviroment. Change some RStudio defaults. Deselect &quot;Restore .RData into workspace at startup. Set “Save workspace .RData on exit:” to “Never” This will save you a lot of headache in STAT 432 and the future. 3.3.2 R Versions You should always use the most up-to-date version of R and RStudio. You must use at least R versions 3.6.2. Importantly, R versions after 3.6.0 have slightly different random number generation. Although, even with the most recent version, sometimes R keeps the old random number generation. To check that you are on the most recent random number generation, run: RNGkind() ## [1] &quot;Mersenne-Twister&quot; &quot;Inversion&quot; &quot;Rejection&quot; If your output matches the output above, you’re all set. If not, run: RNGversion(getRversion()) Then re-run RNGkind() and everything should match up and you should be go to go! 3.3.3 Code Style Code needs to be read by two distinct groups: Computers Humans Computers will complain, very loudly, when you write “bad” code, that is code does not run. We need to write code that is syntactically correct for the computer to be able to “read” our code. Computers only care about syntax. If we relate this to natural language, we would say that computers really only care about grammar and punctuation. They don’t worry about style like phrasing, tone, etc. While computers will complain about bad code, does anyone really care about wasting their time? (OK, sure, computer scientists might.) If we give them bad code, they try to run it, fail, then complain. However, they’re soulless machines, they can handle it. Humans on the other hand have a finite amount of time on this earth. Even if we solve aging, we still have to deal with the heat death of the universe. Thus, while wasting a computer’s time is no big deal, wasting a human’s time is, frankly, immoral. What does this have to do with R programming? Humans are going to read your R code. One of those humans is likely to be you, but future you. To make this reading possible and efficient, you need to develop style. Here is some code that a computer can read, but a human will struggle to read: set.seed(1337);mu=10;sample_size=50;samples=100000;x_bars=rep(0, samples); for(i in 1:samples){x_bars[i]=mean(rpois(sample_size,lambda = mu))} x_bar_hist=hist(x_bars,breaks=50,main=&quot;Histogram of Sample Means&quot;, xlab=&quot;Sample Means&quot;,col=&quot;darkorange&quot;,border = &quot;dodgerblue&quot;) Now, written again, but readable by a human: # set seed for reproducibility set.seed(1337) # setup simulation parameters mu = 10 sample_size = 50 samples = 100000 # create vector to store simulation results x_bars = rep(0, samples) # run simulation for (i in 1:samples) { x_bars[i] = mean(rpois(sample_size, lambda = mu)) } # plot results x_bar_hist = hist( x_bars, breaks = 50, main = &quot;Histogram of Sample Means&quot;, xlab = &quot;Sample Means&quot;, col = &quot;darkorange&quot;, border = &quot;dodgerblue&quot; ) To the computer, these are the same. To a human, one makes you want to pull your hair out, the other you can glance at and have a pretty good idea about what is going on. Style is subjective, but we’ll define some guiding principles, and a few rules. 3.3.4 Reference Style So as to not have to define a style from the ground up, we will use the tidyverse style as our initial reference. tidyverse Style Guide We will agree with the vast majority of the guidelines here. The exceptions are listed in the next section. 3.3.5 STAT 432 R Style Overrides All commas must be followed by a space. (Additionally, commas should never be preceded by a space.) Infix operators (==, +, -, &lt;-, etc.) should always be surrounded by spaces. Exceptions: :, ::, $, [, [[, ], ]] ^: Use x ^ 2 instead of x^2. You may use = instead of &lt;-. This is very much a minority position in the R community. But we see more examples of it being promoted every day. My reasoning for this is complicated (and I should write more about it soon) but not super important. Instead, what is important: Do not mix assignment operators. Either use = or use &lt;- but do not mix and match in the same script. Never use T or F, only TRUE or FALSE. While this should never happen, take a look at this terrifying example. FALSE == TRUE # checking for equality ## [1] FALSE F == TRUE # checking for equality ## [1] FALSE F = TRUE # A VERY BAD ASSIGNMENT! DO NOT DO THIS! F == TRUE # checking for equality, with a wild result! ## [1] TRUE # TRUE = FALSE # This won&#39;t run, which is good! Do not use ;. This is mostly a readability issue. Do not use attach(). Without going into the details, you will save yourself a lot of headache someday if you follow this advice. Do not use &lt;&lt;-. You probably didn’t know this exists. Pretend that is still the case. Do not set a working directory by using setwd() or any other method. This will make your scripts and R Markdown documents much more reproducible. Do not use absolute paths. Place a space after any # used to create a comment. No more than one newline (blank line) in a row Do not put spaces in filenames. Use dashes - or underscores _. Also consider only using lowercase. Load all packages before setting a seed. Opening (left) curly braces should not be on their own line. Except for the first argument to a function, argument names should be written in function calls. (Exception for the predict() function. Do not name the section argument to the predict() function.) Place a newline at the end of the file. 3.3.6 STAT 432 R Markdown Style Some of the previous section applies here as well, but additionally, some more specific R Markdown style guidelines: No more than one newline (blank line) in a row in an R Markdown document. No more than one newline (blank line) in a row in an R chunk. A newline before and after each chunk in an R Markdown document. No newline to start a chunk. No newline at end of chunk. (The first and last line of each chunk should contain code, or a comment for the first line.) Use headers appropriately! (Short names, good structure.) Load all needed packages at the beginning of an analysis in a single chunk. One plot per chunk! Plotting chunks should return one plot and nothing else. (No numeric printing.) 3.3.7 Style Heuristics Now that we’ve overwhelmed you with information about style, will leave you with the real advise. The most important thing to consider when evaluating the style of your code is consistency. In order, you should be consistent: with yourself! with your group! with your organization! Blindly following the rules is foolish. Breaking rules can be fun! If you do it in a way that makes life easier for everyone, by all mean, do it. 3.3.8 Objects and Functions To understand computations in R, two slogans are helpful: Everything that exists is an object. Everything that happens is a function call. — John Chambers As you continue to sharper your R skills, keep this quotation in mind. Eventually, you will realize that everything you “do” in R, you do by running a function. To debug your code, you will need to explore the objects returned by functions. To fix your code, you will need to alter the inputs to functions, which are objects. In STAT 432, the objects that we will encounter will almost always be: vectors, lists data frames model objects (Mostly lists with a class of the model type.) If you become proficient at creating, manipulating, and accessing these objects, you will likely have success in STAT 432. 3.3.9 Print versus Return One of the more confusing aspects of R is the difference between what is returned when running a function, and what is printed when running a function (interactively) as a user. Consider fitting the following linear model. cars_mod = lm(dist ~ speed, data = cars) You might think that you can simply type cars_mod to see what was returned by lm(). cars_mod ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Coefficients: ## (Intercept) speed ## -17.579 3.932 However, this is not what was returned. This is what was printed. To better understand what was returned, we use the `str() function. str(cars_mod) ## List of 12 ## $ coefficients : Named num [1:2] -17.58 3.93 ## ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;(Intercept)&quot; &quot;speed&quot; ## $ residuals : Named num [1:50] 3.85 11.85 -5.95 12.05 2.12 ... ## ..- attr(*, &quot;names&quot;)= chr [1:50] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ effects : Named num [1:50] -303.914 145.552 -8.115 9.885 0.194 ... ## ..- attr(*, &quot;names&quot;)= chr [1:50] &quot;(Intercept)&quot; &quot;speed&quot; &quot;&quot; &quot;&quot; ... ## $ rank : int 2 ## $ fitted.values: Named num [1:50] -1.85 -1.85 9.95 9.95 13.88 ... ## ..- attr(*, &quot;names&quot;)= chr [1:50] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ assign : int [1:2] 0 1 ## $ qr :List of 5 ## ..$ qr : num [1:50, 1:2] -7.071 0.141 0.141 0.141 0.141 ... ## .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. ..$ : chr [1:50] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## .. .. ..$ : chr [1:2] &quot;(Intercept)&quot; &quot;speed&quot; ## .. ..- attr(*, &quot;assign&quot;)= int [1:2] 0 1 ## ..$ qraux: num [1:2] 1.14 1.27 ## ..$ pivot: int [1:2] 1 2 ## ..$ tol : num 1e-07 ## ..$ rank : int 2 ## ..- attr(*, &quot;class&quot;)= chr &quot;qr&quot; ## $ df.residual : int 48 ## $ xlevels : Named list() ## $ call : language lm(formula = dist ~ speed, data = cars) ## $ terms :Classes &#39;terms&#39;, &#39;formula&#39; language dist ~ speed ## .. ..- attr(*, &quot;variables&quot;)= language list(dist, speed) ## .. ..- attr(*, &quot;factors&quot;)= int [1:2, 1] 0 1 ## .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. .. ..$ : chr [1:2] &quot;dist&quot; &quot;speed&quot; ## .. .. .. ..$ : chr &quot;speed&quot; ## .. ..- attr(*, &quot;term.labels&quot;)= chr &quot;speed&quot; ## .. ..- attr(*, &quot;order&quot;)= int 1 ## .. ..- attr(*, &quot;intercept&quot;)= int 1 ## .. ..- attr(*, &quot;response&quot;)= int 1 ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_GlobalEnv&gt; ## .. ..- attr(*, &quot;predvars&quot;)= language list(dist, speed) ## .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:2] &quot;numeric&quot; &quot;numeric&quot; ## .. .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;dist&quot; &quot;speed&quot; ## $ model :&#39;data.frame&#39;: 50 obs. of 2 variables: ## ..$ dist : num [1:50] 2 10 4 22 16 10 18 26 34 17 ... ## ..$ speed: num [1:50] 4 4 7 7 8 9 10 10 10 11 ... ## ..- attr(*, &quot;terms&quot;)=Classes &#39;terms&#39;, &#39;formula&#39; language dist ~ speed ## .. .. ..- attr(*, &quot;variables&quot;)= language list(dist, speed) ## .. .. ..- attr(*, &quot;factors&quot;)= int [1:2, 1] 0 1 ## .. .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. .. .. ..$ : chr [1:2] &quot;dist&quot; &quot;speed&quot; ## .. .. .. .. ..$ : chr &quot;speed&quot; ## .. .. ..- attr(*, &quot;term.labels&quot;)= chr &quot;speed&quot; ## .. .. ..- attr(*, &quot;order&quot;)= int 1 ## .. .. ..- attr(*, &quot;intercept&quot;)= int 1 ## .. .. ..- attr(*, &quot;response&quot;)= int 1 ## .. .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_GlobalEnv&gt; ## .. .. ..- attr(*, &quot;predvars&quot;)= language list(dist, speed) ## .. .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:2] &quot;numeric&quot; &quot;numeric&quot; ## .. .. .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;dist&quot; &quot;speed&quot; ## - attr(*, &quot;class&quot;)= chr &quot;lm&quot; This is a huge mess, but most importantly, at the top we are told that cars_mod is a list. (It’s technically a object of class &quot;lm&quot;, but it functions like a list.) class(cars_mod) ## [1] &quot;lm&quot; is.list(cars_mod) ## [1] TRUE Thus to access certain information returned by lm() we need to access cars_mod as a list. cars_mod$coefficients ## (Intercept) speed ## -17.579095 3.932409 Note that what is returned here is a vector, so we could pull out a particular value using vector syntax. is.vector(cars_mod$coefficients) ## [1] TRUE cars_mod$coefficients[&quot;speed&quot;] ## speed ## 3.932409 Since lm() truly returns an object of type &quot;lm&quot; we can pass cars_mods to some generic functions, and then specific versions for objects of type &quot;lm&quot; will be used. coef(cars_mod) ## (Intercept) speed ## -17.579095 3.932409 predict(cars_mod, data.frame(speed = 5:10)) ## 1 2 3 4 5 6 ## 2.082949 6.015358 9.947766 13.880175 17.812584 21.744993 summary(cars_mod) ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -29.069 -9.525 -2.272 9.215 43.201 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -17.5791 6.7584 -2.601 0.0123 * ## speed 3.9324 0.4155 9.464 1.49e-12 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 15.38 on 48 degrees of freedom ## Multiple R-squared: 0.6511, Adjusted R-squared: 0.6438 ## F-statistic: 89.57 on 1 and 48 DF, p-value: 1.49e-12 Hey, wait, what is returned by summary()? class(summary(cars_mod)) ## [1] &quot;summary.lm&quot; is.list(summary(cars_mod)) ## [1] TRUE The summary() function returns an object of type &quot;summary.lm&quot; which functions as a list! summary(cars_mod)$fstatistic ## value numdf dendf ## 89.56711 1.00000 48.00000 You can also use the View() function, which is specific to RStudio, to view the structure of any object. View(summary(cars_mod)) # RStudio only 3.3.10 Help To get documentation about a function in R, simply put a question mark in front of the function name and RStudio will display the documentation, for example: ?log ?sin ?paste ?lm Frequently one of the most difficult things to do when learning R is asking for help. First, you need to decide to ask for help, then you need to know how to ask for help. Your very first line of defense should be to Google your error message or a short description of your issue. (The ability to solve problems using this method is quickly becoming an extremely valuable skill.) If that fails, and it eventually will, you should ask for help. There are a number of things you should include when emailing an instructor, or posting to a help website such as Stack Exchange. Describe what you expect the code to do. State the end goal you are trying to achieve. (Sometimes what you expect the code to do, is not what you want to actually do.) Provide the full text of any errors you have received. Provide enough code to recreate the error. That is, create a minimal reproducible example. If you follow these steps, you will get your issue resolved much quicker, and possibly learn more in the process. Do not be discouraged by running into errors and difficulties when learning R. (Or any technical skill.) It is simply part of the learning process. While taking STAT 432: Come to office hours! 3.3.11 Keyboard Shortcuts This section should be expanded over time, but for now, two strong suggestions: Get in the habit of using the keyboard as much as possible, and the mouse as little as possible. A keyboard is a precise entry tool, a mouse is not. Using a mouse requires you to move your hands, a keyboard does not. Hit the [TAB] key often. Like, all the time. It will autocomplete function and object names. It will autofill argument names. (This removes the need to memorize arguments!) 3.3.12 Common Issues As they arise throughout the semester, we will try to track and explain common issues here. 3.4 Source R Markdown: 03-computing.Rmd "],
["probability.html", "Chapter 4 Probability 4.1 Reading 4.2 Probability Models 4.3 Probability Axioms 4.4 Probability Rules 4.5 Random Variables 4.6 Expectations 4.7 Likelihood 4.8 References 4.9 Source", " Chapter 4 Probability STAT 432 is not a course about probability. STAT 432 is a course that uses probability. We give a very brief review of some necessary probability concepts. As the treatment is less than complete, a list of references is given at the end of the chapter. For example, we ignore the usual recap of basic set theory and omit proofs and examples. Reading the information below will likely be unsatisfying. Instead, we suggest that you skip it, engage with the relevant quizzes, then return as needed for reference. 4.1 Reading Required: Probability Distributions in R Reference: STAT 400 @ UIUC: Notes and Homework Reference: MIT 6.041: Video Lectures Reference: MIT 6.041: Lecture Notes Reference: MIT 6.041: Readings Reference: STAT 414 @ PSU: Notes 4.2 Probability Models When discussing probability models, we speak of random experiments that produce one of a number of possible outcomes. A probability model that describes the uncertainty of an experiment consists of two elements: The sample space, often denoted as \\(\\Omega\\), which is a set that contains all possible outcomes. A probability function that assigns to an event \\(A\\) a nonnegative number, \\(P[A]\\), that represents how likely it is that event \\(A\\) occurs as a result of the experiment. We call \\(P[A]\\) the probability of event \\(A\\). An event \\(A\\) could be any subset of the sample space, not necessarily a single possible outcome. The probability law must follow a number of rules, which are the result of a set of axioms that we introduce now. 4.3 Probability Axioms Given a sample space \\(\\Omega\\) for a particular experiment, the probability function associated with the experiment must satisfy the following axioms. Nonnegativity: \\(P[A] \\geq 0\\) for any event \\(A \\subset \\Omega\\). Normalization: \\(P[\\Omega] = 1\\). That is, the probability of the entire space is 1. Additivity: For mutually exclusive events \\(E_1, E_2, \\ldots\\) \\[ P\\left[\\bigcup_{i = 1}^{\\infty} E_i\\right] = \\sum_{i = 1}^{\\infty} P[E_i] \\] Using these axioms, many additional probability rules can easily be derived. 4.4 Probability Rules Given an event \\(A\\), and its complement, \\(A^c\\), that is, the outcomes in \\(\\Omega\\) which are not in \\(A\\), we have the complement rule: \\[ P[A^c] = 1 - P[A] \\] In general, for two events \\(A\\) and \\(B\\), we have the addition rule: \\[ P[A \\cup B] = P[A] + P[B] - P[A \\cap B] \\] If \\(A\\) and \\(B\\) are also disjoint, then we have: \\[ P[A \\cup B] = P[A] + P[B] \\] If we have \\(n\\) mutually exclusive events, \\(E_1, E_2, \\ldots E_n\\), then we have: \\[ P\\left[\\textstyle\\bigcup_{i = 1}^{n} E_i\\right] = \\sum_{i = 1}^{n} P[E_i] \\] Often, we would like to understand the probability of an event \\(A\\), given some information about the outcome of event \\(B\\). In that case, we have the conditional probability rule provided \\(P[B] &gt; 0\\). \\[ P[A \\mid B] = \\frac{P[A \\cap B]}{P[B]} \\] Rearranging the conditional probability rule, we obtain the multiplication rule: \\[ P[A \\cap B] = P[B] \\cdot P[A \\mid B] \\cdot \\] For a number of events \\(E_1, E_2, \\ldots E_n\\), the multiplication rule can be expanded into the chain rule: \\[ P\\left[\\textstyle\\bigcap_{i = 1}^{n} E_i\\right] = P[E_1] \\cdot P[E_2 \\mid E_1] \\cdot P[E_3 \\mid E_1 \\cap E_2] \\cdots P\\left[E_n \\mid \\textstyle\\bigcap_{i = 1}^{n - 1} E_i\\right] \\] Define a partition of a sample space \\(\\Omega\\) to be a set of disjoint events \\(A_1, A_2, \\ldots, A_n\\) whose union is the sample space \\(\\Omega\\). That is \\[ A_i \\cap A_j = \\emptyset \\] for all \\(i \\neq j\\), and \\[ \\bigcup_{i = 1}^{n} A_i = \\Omega. \\] Now, let \\(A_1, A_2, \\ldots, A_n\\) form a partition of the sample space where \\(P[A_i] &gt; 0\\) for all \\(i\\). Then for any event \\(B\\) with \\(P[B] &gt; 0\\) we have Bayes’ Theorem: \\[ P[A_i | B] = \\frac{P[A_i]P[B | A_i]}{P[B]} = \\frac{P[A_i]P[B | A_i]}{\\sum_{i = 1}^{n}P[A_i]P[B | A_i]} \\] The denominator of the latter equality is often called the law of total probability: \\[ P[B] = \\sum_{i = 1}^{n}P[A_i]P[B | A_i] \\] Note: When working with Bayes’ Theorem it is often useful to draw a tree diagram. Two events \\(A\\) and \\(B\\) are said to be independent if they satisfy \\[ P[A \\cap B] = P[A] \\cdot P[B] \\] This becomes the new multiplication rule for independent events. A collection of events \\(E_1, E_2, \\ldots E_n\\) is said to be independent if \\[ P\\left[\\bigcap_{i \\in S} E_i \\right] = \\prod_{i \\in S}P[E_i] \\] for every subset \\(S\\) of \\(\\{1, 2, \\ldots n\\}\\). If this is the case, then the chain rule is greatly simplified to: \\[ P\\left[\\textstyle\\bigcap_{i = 1}^{n} E_i\\right] = \\prod_{i=1}^{n}P[E_i] \\] 4.5 Random Variables A random variable is simply a function which maps outcomes in the sample space to real numbers. 4.5.1 Distributions We often talk about the distribution of a random variable, which can be thought of as: \\[ \\text{distribution} = \\text{list of possible} \\textbf{ values} + \\text{associated} \\textbf{ probabilities} \\] This is not a strict mathematical definition, but is useful for conveying the idea. If the possible values of a random variables are discrete, it is called a discrete random variable. If the possible values of a random variables are continuous, it is called a continuous random variable. 4.5.2 Discrete Random Variables The distribution of a discrete random variable \\(X\\) is most often specified by a list of possible values and a probability mass function, \\(p(x)\\). The mass function directly gives probabilities, that is, \\[ p(x) = p_X(x) = P[X = x]. \\] Note we almost always drop the subscript from the more correct \\(p_X(x)\\) and simply refer to \\(p(x)\\). The relevant random variable is discerned from context The most common example of a discrete random variable is a binomial random variable. The mass function of a binomial random variable \\(X\\), is given by \\[ p(x | n, p) = {n \\choose x} p^x(1 - p)^{n - x}, \\ \\ \\ x = 0, 1, \\ldots, n, \\ n \\in \\mathbb{N}, \\ 0 &lt; p &lt; 1. \\] This line conveys a large amount of information. The function \\(p(x | n, p)\\) is the mass function. It is a function of \\(x\\), the possible values of the random variable \\(X\\). It is conditional on the parameters \\(n\\) and \\(p\\). Different values of these parameters specify different binomial distributions. \\(x = 0, 1, \\ldots, n\\) indicates the sample space, that is, the possible values of the random variable. \\(n \\in \\mathbb{N}\\) and \\(0 &lt; p &lt; 1\\) specify the parameter spaces. These are the possible values of the parameters that give a valid binomial distribution. Often all of this information is simply encoded by writing \\[ X \\sim \\text{bin}(n, p). \\] 4.5.3 Continuous Random Variables The distribution of a continuous random variable \\(X\\) is most often specified by a set of possible values and a probability density function, \\(f(x)\\). (A cumulative density or moment generating function would also suffice.) The probability of the event \\(a &lt; X &lt; b\\) is calculated as \\[ P[a &lt; X &lt; b] = \\int_{a}^{b} f(x)dx. \\] Note that densities are not probabilities. The most common example of a continuous random variable is a normal random variable. The density of a normal random variable \\(X\\), is given by \\[ f(x | \\mu, \\sigma^2) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\cdot \\exp\\left[\\frac{-1}{2} \\left(\\frac{x - \\mu}{\\sigma}\\right)^2 \\right], \\ \\ \\ -\\infty &lt; x &lt; \\infty, \\ -\\infty &lt; \\mu &lt; \\infty, \\ \\sigma &gt; 0. \\] The function \\(f(x | \\mu, \\sigma^2)\\) is the density function. It is a function of \\(x\\), the possible values of the random variable \\(X\\). It is conditional on the parameters \\(\\mu\\) and \\(\\sigma^2\\). Different values of these parameters specify different normal distributions. \\(-\\infty &lt; x &lt; \\infty\\) indicates the sample space. In this case, the random variable may take any value on the real line. \\(-\\infty &lt; \\mu &lt; \\infty\\) and \\(\\sigma &gt; 0\\) specify the parameter space. These are the possible values of the parameters that give a valid normal distribution. Often all of this information is simply encoded by writing \\[ X \\sim N(\\mu, \\sigma^2) \\] 4.5.4 Distributions in R R is an excellent, if not best, tool for performing probability distribution calculations. For a large number of distributions, it has four built in functions: d*(x, ...) returns the PDF at \\(x\\) (for continuous distributions) or the PMG at \\(x\\) (for discrete distributions) p*(q, ...) returns the CDF at quantile \\(q\\), that is \\(P[X \\leq q]\\) q*(p, ...) returns \\(c\\) such that \\(P[x \\leq c] = p\\) r*(n, ...) returns \\(n\\) randomly generated observations The * can be any of the disributions built in to R. The ... represents additional arguments, including the parameters of the various distributions. 4.5.5 Several Random Variables Consider two random variables \\(X\\) and \\(Y\\). We say they are independent if \\[ f(x, y) = f(x) \\cdot f(y) \\] for all \\(x\\) and \\(y\\). Here \\(f(x, y)\\) is the joint density (mass) function of \\(X\\) and \\(Y\\). We call \\(f(x)\\) the marginal density (mass) function of \\(X\\). Then \\(f(y)\\) the marginal density (mass) function of \\(Y\\). The joint density (mass) function \\(f(x, y)\\) together with the possible \\((x, y)\\) values specify the joint distribution of \\(X\\) and \\(Y\\). Similar notions exist for more than two variables. 4.6 Expectations For discrete random variables, we define the expectation of the function of a random variable \\(X\\) as follows. \\[ \\mathbb{E}[g(X)] \\triangleq \\sum_{x} g(x)p(x) \\] For continuous random variables we have a similar definition. \\[ \\mathbb{E}[g(X)] \\triangleq \\int g(x)f(x) dx \\] For specific functions \\(g\\), expectations are given names. The mean of a random variable \\(X\\) is given by \\[ \\mu_{X} = \\text{mean}[X] \\triangleq \\mathbb{E}[X]. \\] So for a discrete random variable, we would have \\[ \\text{mean}[X] = \\sum_{x} x \\cdot p(x) \\] For a continuous random variable we would simply replace the sum by an integral. The variance of a random variable \\(X\\) is given by \\[ \\sigma^2_{X} = \\text{var}[X] \\triangleq \\mathbb{E}[(X - \\mathbb{E}[X])^2] = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2. \\] The standard deviation of a random variable \\(X\\) is given by \\[ \\sigma_{X} = \\text{sd}[X] \\triangleq \\sqrt{\\sigma^2_{X}} = \\sqrt{\\text{var}[X]}. \\] The covariance of random variables \\(X\\) and \\(Y\\) is given by \\[ \\text{cov}[X, Y] \\triangleq \\mathbb{E}[(X - \\mathbb{E}[X])(Y - \\mathbb{E}[Y])] = \\mathbb{E}[XY] - \\mathbb{E}[X] \\cdot \\mathbb{E}[Y]. \\] 4.7 Likelihood Consider \\(n\\) iid random variables \\(X_1, X_2, \\ldots X_n\\). We can then write their likelihood as \\[ \\mathcal{L}(\\theta \\mid x_1, x_2, \\ldots x_n) \\triangleq f(x_1, x_2, \\ldots, x_n; \\theta) = \\prod_{i = 1}^n f(x_i; \\theta) \\] where \\(f(x_1, x_2, \\ldots, x_n; \\theta)\\) is the joint density (or mass) of \\(X_1, X_2, \\ldots X_n\\) and \\(f(x_i; \\theta)\\) is the density (or mass) function of random variable \\(X_i\\) evaluated at \\(x_i\\) with parameter \\(\\theta\\). (Note: The last equality above only holds for iid random variables.) Whereas a probability or density is a function of a possible observed value given a particular parameter value, a likelihood is the opposite. It is a function of a possible parameter values given observed data. Likelihoods are calculated when the data (the \\(x_i\\)) are known and the parameters (\\(\\theta\\)) are unknown. That is, a likelihood and a joint density will “look” the same, that is contain the same symbols. The meaning of these symbols change depending on what is known. If the data is known, and the parameters is unknown, you have a likelihood. If the parameters are known, and the data are unknown, you have a joint density. The definition above is an acknowledgement of this. The likelihood is defined to be the joint density when the data are known but the parameter(s) is unknown. Maximizing a likelihood is a common technique for fitting a model to data, however, most often we maximum the log-likelihood, as the likelihood and log-likelihood obtain their maximum at the same point. \\[ \\log \\mathcal{L}(\\theta \\mid x_1, x_2, \\ldots x_n) = \\sum_{i = 1}^{n} \\log f(x_i; \\theta) \\] As an example, suppose that the data vector x_data contains observations from a random sample \\(X_1, X_2, \\ldots, X_n\\) that is assumed to be sampled from a Poisson distribution with (unknown) parameter \\(\\lambda\\). set.seed(42) x_data = rpois(n = 25, lambda = 6) # generating data (assume this is not known) head(x_data) # check data ## [1] 9 10 5 8 7 6 We can use R to calculate the likelihood for various possible values of \\(\\lambda\\) given this data. # calculate the likelihood when lambda = 5 prod(dpois(x = x_data, lambda = 5)) ## [1] 2.609375e-30 The above code takes advantage of the vectorized nature of the dpois() function. Often, especially for computational reasons, we prefer to directly obtain the log-likelihood. # calculate the log-likelihood when lambda = 5 sum(log(dpois(x = x_data, lambda = 5))) ## [1] -68.11844 To understand why this is necessary, repeat the above, but with a much larger sample size. Also note that the d*() functions in R have an option to return logged values. # calculate the log-likelihood when lambda = 5 sum(dpois(x = x_data, lambda = 5, log = TRUE)) ## [1] -68.11844 4.8 References Any of the following are either dedicated to, or contain a good coverage of the details of the topics above. Probability Texts Introduction to Probability by Dimitri P. Bertsekas and John N. Tsitsiklis A First Course in Probability by Sheldon Ross Machine Learning Texts with Probability Focus Probability for Statistics and Machine Learning by Anirban DasGupta Machine Learning: A Probabilistic Perspective by Kevin P. Murphy Statistics Texts with Introduction to Probability Probability and Statistical Inference by Robert V. Hogg, Elliot Tanis, and Dale Zimmerman Introduction to Mathematical Statistics by Robert V. Hogg, Joseph McKean, and Allen T. Craig 4.8.1 Videos The YouTube channel mathematicalmonk has a great Probability Primer playlist containing lectures on many fundamental probability concepts. Some of the more important concepts are covered in the following videos: Conditional Probability Independence More Independence Bayes Rule 4.9 Source R Markdown: 04-probability.Rmd "],
["statistics.html", "Chapter 5 Statistics 5.1 Reading 5.2 Statistics 5.3 Estimators 5.4 Source", " Chapter 5 Statistics STAT 432 is a course about statistics, in particular, some specific statistics. To discuss the statistics of interest in STAT 432, we will need some general concepts about statistics. Note: This section has been published while being nearly empty to provide easy access to a few definitions needed for Quiz 01. Additional information was added ahead of Quiz 02, but it is still very sparse as it is difficult to summarize all of statistics in one chapter. In reality we just need to state a few definitions here and then move on to the next chapter, where the fun begins. 5.1 Reading Reference: STAT 400 @ UIUC: Notes and Homework Reference: STAT 3202 @ OSU: Fitting a Probability Model Reference: STAT 415 @ PSU: Notes 5.2 Statistics In short: a statistic is a function of (sample) data. (This mirrors parameters being functions of (population) distributions. In SAT terminology, statistics : data :: parameter : distribution.) Consider a random variable \\(X\\), with PDF \\(f(x)\\) which defines the distribution of \\(X\\). Now consider the parameter \\(\\mu\\), which we usually refer to as the mean of a distribution. We use \\(\\mu_X\\) to note that \\(\\mu\\) is dependent on the distribution of \\(X\\). \\[ \\mu_X = \\text{E}[X] = \\int_{-\\infty}^{\\infty}xf(x)dx \\] Note that this expression is a function of \\(f(x)\\). When we change the distribution of \\(X\\), that is, it has a different \\(f(x)\\), that effects \\(\\mu\\). Now, given a random sample \\(X_1, X_2, \\ldots, X_n\\), define a statistic, \\[ \\hat{\\mu}(x_1, x_2, \\ldots, x_n) = \\frac{1}{n}\\sum_{i = 1}^{n}x_i \\] Often, we will simplify notation and instead simply write \\[ \\hat{\\mu} = \\frac{1}{n}\\sum_{i = 1}^{n}x_i \\] and the fact that \\(\\hat{\\mu}\\) is a function of the sample is implied. (You might also notice that this is the sample mean, which is often denoted by \\(\\bar{x}\\).) Another confusing aspect of statistics is that they are random variables! Sometimes we would write the above as \\[ \\hat{\\mu}(X_1, X_2, \\ldots, X_n) = \\frac{1}{n}\\sum_{i = 1}^{n}X_i \\] When written this way, we are emphasizing that the random sample has not yet be observed, thus is still random. When this is the case, we can investigate the properties of the statistic as a random variable. When the sample has been observed, we use \\(x_1, x_2, \\ldots, x_n\\) to note that we are inputting these observed values into a function, which outputs some value. (Sometimes we, and others, will be notationally sloppy and simply use lower case \\(x\\) and you will be expected to understand via context if we are dealing with random variables or observed values of random variables. This is admittedly confusing.) As a final note, suppose we observe some data \\[ x_1 = 2, x_2 = 1, x_3 =5 \\] and we calculate \\(\\hat{\\mu}\\) given these values. We would obtain \\[ \\hat{\\mu} = \\frac{8}{3} \\approx 2.66 \\] Note that 2.66 is not a statistic. It is the value of a statistic given a particular set of data. The statistic is still \\(\\hat{\\mu}\\) which has output the value 2.66. Statistics output values given some data. 5.3 Estimators Estimators are just statistics with a purpose, that is, estimators are statistics that attempt to estimate some quantity of interest, usually some parameter. (In other words, learn from data.) Like statistics, estimators are functions of data that output values, which we call estimates. 5.3.1 Properties Bias and Variance Visually Illustrated Because they are just statistics, estimators are simply functions of data. What makes an estimator good? Essentially, an estimator is good if it produces estimates that are close to the thing being estimated. The following properties help to better define this “closeness” as a function of the errors made by estimators. To estimate some parameter \\(\\theta\\) we will consider some estimator \\(\\hat{\\theta}\\). 5.3.1.1 Bias The bias of an estimator defines the systematic error of the estimator, that is, how the estimator “misses” on average. \\[ \\text{bias}\\left[\\hat{\\theta}\\right] \\triangleq \\mathbb{E}\\left[\\hat{\\theta}\\right] - \\theta \\] 5.3.1.2 Variance The variance of an estimator defines how close resulting estimates are to each other. (Assuming the estimated was repeated.) \\[ \\text{var}\\left[\\hat{\\theta}\\right] \\triangleq \\mathbb{E}\\left[ \\left( \\hat{\\theta} - \\mathbb{E}\\left[\\hat{\\theta}\\right] \\right)^2 \\right] \\] 5.3.1.3 Mean Squared Error The mean squared error (MSE) is exactly what the name suggests, it is the average squared error of the estimator. Interestingly, the MSE decomposes into terms related to the bias and the variance. We will return to this idea later for a detailed discussion in the context of machine learning. \\[ \\text{MSE}\\left[\\hat{\\theta}\\right] \\triangleq \\mathbb{E}\\left[\\left(\\hat{\\theta} - \\theta\\right)^2\\right] = \\left(\\text{bias}\\left[\\hat{\\theta}\\right]\\right)^2 + \\text{var}\\left[\\hat{\\theta}\\right] \\] 5.3.1.4 Consistency An estimator \\(\\hat{\\theta}_n\\) is said to be a consistent estimator of \\(\\theta\\) if, for any positive \\(\\epsilon\\), \\[ \\lim_{n \\rightarrow \\infty} P\\left( \\left| \\hat{\\theta}_n - \\theta \\right| \\leq \\epsilon\\right) =1 \\] or, equivalently, \\[ \\lim_{n \\rightarrow \\infty} P\\left( \\left| \\hat{\\theta}_n - \\theta \\right| &gt; \\epsilon\\right) =0 \\] We say that \\(\\hat{\\theta}_n\\) converges in probability to \\(\\theta\\) and we write \\(\\hat{\\theta}_n \\overset P \\rightarrow \\theta\\). 5.3.2 Example: MSE of an Estimator Consider \\(X_1, X_2, X_3 \\sim N(\\mu, \\sigma^2)\\). Define two estimators for the true mean, \\(\\mu\\). \\[ \\bar{X} = \\frac{1}{n}\\sum_{i = 1}^{3} X_i \\] \\[ \\hat{\\mu} = \\frac{1}{4}X_1 + \\frac{1}{5}X_2 + \\frac{1}{6}X_3 \\] We will now calculate and compare the mean squared error of both \\(\\bar{X}\\) and \\(\\hat{\\mu}\\) as estimators of \\(\\mu\\). First, recall from properties of the sample mean that \\[ \\text{E}\\left[\\bar{X}\\right] = \\mu \\] and \\[ \\text{var}\\left[\\bar{X}\\right] = \\frac{\\sigma^2}{3} \\] Thus we have \\[ \\text{bias}\\left[\\bar{X}\\right] = \\mathbb{E}\\left[\\bar{X}\\right] - \\mu = \\mu - \\mu = 0 \\] Then, \\[ \\text{MSE}\\left[\\bar{X}\\right] \\triangleq \\left(\\text{bias}\\left[\\bar{X}\\right]\\right)^2 + \\text{var}\\left[\\bar{X}\\right] = 0 + \\frac{\\sigma^2}{3} = \\frac{\\sigma^2}{3} \\] Next, \\[ \\text{E}\\left[\\hat{\\mu}\\right] = \\frac{\\mu}{4} + \\frac{\\mu}{5} + \\frac{\\mu}{6} = \\frac{37}{60}\\mu \\] and \\[ \\text{var}\\left[\\hat{\\mu}\\right] = \\frac{\\sigma^2}{16} + \\frac{\\sigma^2}{25} + \\frac{\\sigma^2}{36} = \\frac{469}{3600}\\sigma^2 \\] Now we have \\[ \\text{bias}\\left[\\hat{\\mu}\\right] = \\mathbb{E}\\left[\\hat{\\mu}\\right] - \\mu = \\frac{37}{60}\\mu - \\mu = \\frac{-23}{60}\\mu \\] Then finally we obtain the mean squared error for \\(\\hat{\\mu}\\), \\[ \\text{MSE}\\left[\\hat{\\mu}\\right] \\triangleq \\left(\\text{bias}\\left[\\hat{\\mu}\\right]\\right)^2 + \\text{var}\\left[\\hat{\\mu}\\right] = \\left( \\frac{-23}{60}\\mu \\right)^2 + \\frac{469}{3600}\\sigma^2 \\] Note that \\(\\text{MSE}\\left[\\hat{\\mu}\\right]\\) is small when \\(\\mu\\) is close to 0. 5.3.3 Estimation Methods So far we have discussed properties of estimators, but how do we create estimators? You could just define a bunch of estimators and then evaluate them to see what works best (an idea we will return to later in the context of ML) but (the field of) statistics has develop some methods that result in estimators with desirable properties. 5.3.4 Maximum Likelihood Estimation Given a random sample \\(X_1, X_2, \\ldots, X_n\\) from a population with parameter \\(\\theta\\) and density or mass \\(f(x; \\theta)\\), we define the likelihood as \\[ \\mathcal{L}(\\theta \\mid x_1, x_2, \\ldots x_n) \\triangleq f(x_1, x_2, \\ldots, x_n; \\theta) = \\prod_{i = 1}^n f(x_i; \\theta) \\] The Maximum Likelihood Estimator, \\(\\hat{\\theta}\\) \\[ \\hat{\\theta} \\triangleq \\underset{\\theta}{\\text{argmax}} \\ \\mathcal{L}(\\theta \\mid x_1, x_2, \\ldots x_n) = \\underset{\\theta}{\\text{argmax}} \\ \\log \\mathcal{L}(\\theta \\mid x_1, x_2, \\ldots x_n) \\] 5.3.4.1 Invariance Principle If \\(\\hat{\\theta}\\) is the MLE of \\(\\theta\\) and the function \\(h(\\theta)\\) is continuous, then \\(h(\\hat{\\theta})\\) is the MLE of \\(h(\\theta)\\). 5.3.5 Method of Moments While it is very unlikely that we will use the Method of Moments in STAT 432, you should still be aware of its existence. 5.3.6 Empirical Distribution Function Consider a random variable \\(X\\) with CDF \\(F(k) = P(X &lt; k)\\) and an iid random sample \\(X_1, X_2, \\ldots, X_n\\). We can estimate \\(F(k)\\) using the Empirical Distribution Function (EDF), \\[ \\hat{F}(k) = \\frac{\\text{# of elements in sample} \\leq k}{n} = \\frac{1}{n} \\sum_{i = 1}^n I(x_i \\leq k) \\] where \\(I(x_i \\leq k)\\) is an indicator such that \\[ I(x_i \\leq k) = \\begin{cases} 1 &amp; \\text{if } x_i \\leq k \\\\ 0 &amp; \\text{if } x_i &gt; k \\end{cases} \\] Given a data vector in R that is assumed to be a random sample, say, y, and some value, say k, it is easy to calculate \\(\\hat{F}(k)\\). set.seed(66) y = rnorm(n = 25, mean = 6, sd = 2.6) # generate sample k = 4 # pick some k head(y) # check data ## [1] 12.042334 6.564140 7.087301 5.503419 5.181420 4.315569 # using the EDF mean(y &lt; k) ## [1] 0.2 # using an estimated normal distribution (not quite using the MLE) pnorm(q = k, mean = mean(y), sd = sd(y)) ## [1] 0.2088465 # using the true (but assumed unknown) CDF pnorm(q = k, mean = 6, sd = 2.6) ## [1] 0.2208782 Note that technically sd(x) does not return the MLE of \\(\\sigma\\) since it uses the unbiased estimator with a denominator of \\(n - 1\\) instead of \\(n\\), but we’re being lazy for the sake of some cleaner code. plot(ecdf(y), col.01line = &quot;white&quot;, verticals = TRUE, do.points = FALSE, xlim = c(0, 15), lwd = 2, lty = 1, ylab = &quot;F(y)&quot;, xlab = &quot;y&quot;, main = &quot;Comparing the EDF to The Truth and MLE&quot;) curve(pnorm(x, mean = 6, sd = 2.6), add = TRUE, xlim = c(0, 15), col = &quot;dodgerblue&quot;, lty = 2, lwd = 2) curve(pnorm(x, mean = mean(y), sd = sd(y)), add = TRUE, xlim = c(0, 15), col = &quot;darkorange&quot;, lty = 3, lwd = 2) legend(&quot;bottomright&quot;, legend = c(&quot;EDF&quot;, &quot;Truth&quot;, &quot;MLE&quot;), col = c(&quot;black&quot;, &quot;dodgerblue&quot;, &quot;darkorange&quot;), lty = 1:3, lwd = 2) grid() We have purposefully used a “small” sample size here so that the EDF is visibly a step function. Modify the code above to increase the sample size. You should notice that the three functions converge as the sample size increases. 5.4 Source R Markdown: 05-statistics.Rmd "],
["linear-regression.html", "Chapter 6 Linear Regression 6.1 Reading 6.2 Explanation versus Prediction 6.3 Setup 6.4 Mathematical Setup 6.5 Linear Regression Models 6.6 Using lm() 6.7 The predict() Function 6.8 Data Splitting 6.9 Regression Metrics 6.10 Example: “Simple” Simulated Data 6.11 Example: Diamonds Data 6.12 Example: Credit Card Data 6.13 Source", " Chapter 6 Linear Regression This chapter will discuss linear regression models, but for a very specific purpose: using linear regression models to make predictions. Specifically, we will discuss: The regression function and estimating conditional means. Using the lm() and predict() functions in R. Data splits to evaluate model performance for machine learning tasks. 6.1 Reading Required: ISL Chapter 3 Skip section 3.6 which is dedicated to R. Consider this reading a review of previous regression knowledge. The information provided in this chapter of BSL will be the relevant material for STAT 432, but it is still worthwhile to read ISL. However note that this chapter of ISL overemphasizes inference, diagnostics, and at times hints too closely to causal claims for novice readers. (We’re not saying the authors are guilty of making the “correlation is not causation error,” instead, we’ve found that we need to be extremely clear about this issue with students in STAT 432.) Reference: STAT 420 @ UIUC: Notes In particular Chapter 10 which discusses model building will be relevant. The section on explanation versus prediction is extremely relevant, although note that it contains some differences in definitions, especially concerning test data. That said, the general ideas are important. 6.2 Explanation versus Prediction Before we even begin to discuss regression, we make a bold announcement: STAT 432 is not a course about inference. It is very possible that there will be zero causal claims in this book. While it would certainly be nice (but extremely difficult) to uncover causal relationships, our focus will be on predictive relationships. Suppose (although it is likely untrue) that there is a strong correlation between wearing a wrist watch, and car accidents. Depending on your frame of reference, you should view this information in very different ways. Suppose you are a car insurance company. This is great news! You can now more accurately predict the number of accidents of your policy holders. For the sake of understanding how much your company will need to pay out in a year, you don’t care what causes accidents, you just want to be able to predict (estimate) the number of accidents. Suppose you are a car driver. As a driver, you want to stay safe. That is, you want to do things that decrease accidents. In this framing, you care about things that cause accidents, not things that predict accidents. In other words, this correlation information should not lead to you throwing away your wrist watch. Disclaimer: Extremely high correlation should not simply be ignored. For example, there is a very high correlation between smoking and lung cancer. (Fun fact: RA Fisher, the most famous statistician, did not believe that smoking caused cancer. It’s actually a part of a larger fasinating story.) However, this strong correlation is not proof that smoking causes lung cancer. Instead, additional study is needed to rule out confounders, establish mechanistic relationships, and more. 6.3 Setup We now introduce the regression task. Regression is a subset of a broader machine learning tasks called supervised learning, which also include classification. (We will return later to discuss supervised learning in general after getting through some specifics of regression and classification.) Stated simply, the regression tasks seeks to estimate (predict) a numeric quantity. For example: Estimating the salary of a baseball player. Estimating the price of a home for sale. Estimating the credit score of a bank customer. Estimating the number of downloads of a podcast. Each of these quantities is some numeric value. The goal of regression is to estimate (predict) these quantities when they are unknown through the use of additional, possibly correlated quantities. 6.4 Mathematical Setup To get a better grasp of what regression is, we move to defining the task mathematically. Consider a random variable \\(Y\\) which represents a response (or outcome or target) variable, and \\(p\\) feature variables \\(\\boldsymbol{X} = (X_1, X_2, \\ldots, X_p)\\). Features are also called covariates or predictors. (We find the “predictors” nomenclature to be problematic when discussing prediction tasks.) In the most common regression setup, we assume that the response variable \\(Y\\) is some function of the features, plus some random noise. \\[ Y = f(\\boldsymbol{X}) + \\epsilon \\] We call \\(f(\\boldsymbol{X})\\) the signal. This \\(f\\) is the function that we would like to learn. We call \\(\\epsilon\\) the noise. We do not want to learn this which we risk if we overfit. (More on this later.) So our goal will be to find some \\(f\\) such that \\(f(\\boldsymbol{X})\\) is close to \\(Y\\). But how do we define close? There are many ways but we will start with, and most often consider, squared error loss. Specifically, we define a loss function, \\[ L(Y, \\boldsymbol{X}) \\triangleq (Y - \\boldsymbol{X}) ^ 2 \\] Now we can clarify the goal of regression, which is to minimize the above loss, on average. We call this the risk of estimating \\(Y\\) using \\(f(\\boldsymbol{X})\\). \\[ R(Y, f(\\boldsymbol{X})) \\triangleq \\mathbb{E}[L(Y, f(\\boldsymbol{X}))] = \\mathbb{E}_{X, Y}[(Y - f(\\boldsymbol{X})) ^ 2] \\] Before attempting to minimize the risk, we first re-write the risk after conditioning on \\(\\boldsymbol{X}\\). \\[ \\mathbb{E}_{\\boldsymbol{X}, Y} \\left[ (Y - f(\\boldsymbol{X})) ^ 2 \\right] = \\mathbb{E}_{\\boldsymbol{X}} \\mathbb{E}_{Y \\mid \\boldsymbol{X}} \\left[ ( Y - f(\\boldsymbol{X}) ) ^ 2 \\mid \\boldsymbol{X} = \\boldsymbol{x} \\right] \\] Minimizing the right-hand side is much easier, as it simply amounts to minimizing the inner expectation with respect to \\(Y \\mid \\boldsymbol{X}\\), essentially minimizing the risk pointwise, for each \\(\\boldsymbol{x}\\). It turns out, that the risk is minimized by the conditional mean of \\(Y\\) given \\(\\boldsymbol{X}\\), \\[ \\mu(\\boldsymbol{x}) \\triangleq \\mathbb{E}[Y \\mid \\boldsymbol{X} = \\boldsymbol{x}] \\] which we call the regression function. Note that \\(\\boldsymbol{x}\\) represents realized values of the random variables \\(\\boldsymbol{X}\\), as discussed in the previous chapter. \\[ \\boldsymbol{x} = (x_1, x_2, \\ldots, x_p) \\] We can now state the goal of the regression task: we want to estimate the regression function. How do we do that? 6.5 Linear Regression Models What do linear regression models do? They estimate the conditional mean of \\(Y\\) given \\(\\boldsymbol{X}\\)! (How convenient.) Consider the following probability model \\[ Y = 1 - 2x - 3x ^ 2 + 5x ^ 3 + \\epsilon \\] where \\(\\epsilon \\sim \\text{N}(0, \\sigma^2)\\). Alternatively we could write \\[ Y \\mid X \\sim \\text{N}(1 - 2x - 3x ^ 2 + 5x ^ 3, \\sigma^2) \\] This perhaps makes it clearer that \\[ \\mu(x) = \\mathbb{E}[Y \\mid \\boldsymbol{X} = \\boldsymbol{x}] = 1 - 2x - 3x ^ 2 + 5x ^ 3 \\] What do linear models do? More specifically than before, linear regression models estimate the conditional mean of \\(Y\\) given \\(\\boldsymbol{X}\\) by assuming this conditional mean is a linear combination of the feature variables. Suppose for a moment that we did not know the above true probability model, or even the more specifically the regression function. Instead, all we had was some data, \\((x_i, y_i)\\) for \\(i = 1, 2, \\ldots, n\\). x y -0.4689827 -0.0580887 -0.2557522 1.7190632 0.1457067 1.3986870 0.8164156 0.6641923 -0.5966361 -0.2419769 0.7967794 1.5428566 0.8893505 0.7554431 0.3215956 -0.4083999 0.2582281 -1.8451058 -0.8764275 -1.7926190 How do we fit (or “train” in the ML language) a linear model with this data? In order words, how to be learn the regression function from this data with a linear regression model? First, we need to make assumptions about the form of the regression function, up to, but not including some unknown parameters. Consider three possible linear models, in particular, three possible regression functions. Degree 1 Polynomial \\[ \\mu(x) = \\beta_0 + \\beta_1 x \\] Degree 3 Polynomial \\[ \\mu(x) = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\beta_3 x^3 \\] Degree 9 Polynomial \\[ \\mu(x) = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\beta_3 x^3 + \\ldots + \\beta_9 x^9 \\] These are chosen mostly arbitrarily for illustrative purposes which we’ll see in a moment. So how do we actually fit these models, that is train them, with the given data. We have a couple of options: Maximum Likelihood or Least Squares! In this case, they actually produce the same result, so we use least squares for simplicity of explanation. To fit the degree 3 polynomial using least squares, we minimize \\[ \\sum_{i = 1}^{n}(y_i - (\\beta_0 + \\beta_1 x_i + \\beta_2 x_i^2 + \\beta_3 x_i^3)) ^ 2 \\] Skipping the details of the minimization, we would acquire \\(\\hat{\\beta}_0\\), \\(\\hat{\\beta}_1\\), \\(\\hat{\\beta}_2\\), and \\(\\hat{\\beta}_3\\) which are estimates of \\({\\beta}_0\\), \\({\\beta}_1\\), \\({\\beta}_2\\), and \\({\\beta}_3\\). Taken together, we would have \\[ \\hat{\\mu}(x) = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\hat{\\beta}_2 x_2^2 + \\hat{\\beta}_3 x_3^3 \\] which is then an estimate of \\(\\mu(x)\\). While in this case, it will almost certainly not be the case that \\(\\hat{\\beta}_0 = 1\\) or \\(\\hat{\\beta}_1 = -2\\) or \\(\\hat{\\beta}_2 = -3\\) or \\(\\hat{\\beta}_3 = 5\\), which are the true values of the \\(\\beta\\) coefficients, they are at least reasonable estimates. As a bit of an aside, note that in this case, it is sort of ambiguous as to whether there is one feature, \\(x\\), which is seen in the data, or three features \\(x\\), \\(x^2\\), and \\(x^3\\), which are seen in the model. The truth is sort of in the middle. The data has a single feature, but through feature engineering, we have created two additional features for fitting the model. Note that when using R, you do not need to modify the data to do this, instead you should use R’s formula syntax to specify this feature engineering when fitting the model. More on this when we discuss the lm() function in R. (We introduce this somewhat confusing notion early so we can emphasize that linear models are about linear combinations of features, not necessarily linear relationships. Although, linear models are very good at learning linear relationships.) Suppose instead we had assumed that \\[ \\mu(x) = \\beta_0 + \\beta_1 x \\] This model is obviously flawed as it doesn’t contain enough terms to capture the true regression function. (Later we will say this model is not “flexible” enough.) Or, suppose we had assumed \\[ \\mu(x) = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\beta_3 x^3 + \\ldots + \\beta_9 x^9 \\] This model is also flawed, but for a different reason. (Later we will say this model is too “flexible.”) After using least squares, we will obtain some \\(\\hat{\\beta}_9\\) even though there is not a 9th degree term in the true regression function! Let’s take a look at this visually. Here we see the three models fit to the data above. The dashed black curve is the true mean function, that is the true mean of \\(Y\\) given \\(x\\), and the solid colored curves are the estimated mean functions. Now we ask the question: which of these models is best? Given these pictures, there are two criteria that we could consider. How close is the estimated regression (mean) function to the data? (Degree 9 is best! There is no error!) How close is the estimated regression (mean) function to the true regression (mean) function? (Degree 3 is best.) From the presentation here, it’s probably clear that the latter is actually what matters. We can demonstrate this by generating some “new” data. These plots match the plots above, except newly simulated data is shown. (The regression functions were still estimated with the previous data.) Note that the degree 3 polynomial matches the data about the same as before. The degree 9 polynomial now correctly predicts none of the new data and makes some huge errors. We will define these concepts more generally later, but for now we note that: The Degree 9 Polynomial is overfitting. It performs well on the data used to fit the model, but poorly on new data. The Degree 1 Polynomial is underfitting. It performs poorly on the data used to fit the model and poorly on new data. There’s a bit of a problem though! In practice, we don’t know the true mean function, and we don’t have the magical ability to simulate new data! Yikes! After we discuss a bit about how to fit these models in R, we’ll return to this issue. (Spoiler: Don’t fit the model to all the available data. Pretend the data you didn’t use is “new” when you evaluate models.) 6.6 Using lm() Before we continue, let’s consider a different data generating process. We first define this data generating process as an R function. gen_mlr_data = function(sample_size = 250) { x1 = round(runif(n = sample_size), 2) x2 = round(runif(n = sample_size), 2) x3 = round(runif(n = sample_size), 2) x4 = factor(sample(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), size = sample_size, replace = TRUE)) x5 = round(runif(n = sample_size), 2) x6 = round(runif(n = sample_size), 2) y = 2 + x1 + sin(x2) + 3 * x3 ^ 2 + 3 * (x4 == &quot;B&quot;) - 2 * (x4 == &quot;C&quot;) + rnorm(n = sample_size, mean = 0, sd = 0.5) tibble(y, x1, x2, x3, x4, x5, x6) } We then run the function and store the data that is returned. set.seed(42) sim_mlr_data = gen_mlr_data() We then inspect the data. head(sim_mlr_data) ## # A tibble: 6 x 7 ## y x1 x2 x3 x4 x5 x6 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2.85 0.91 0.33 0.14 A 0.53 0.24 ## 2 6.22 0.94 0.19 0.18 B 0.7 0.51 ## 3 6.71 0.290 0.27 0.52 B 0.05 0.51 ## 4 7.84 0.83 0.53 0.81 B 0.92 0.76 ## 5 2.75 0.64 0.02 0.12 A 0.03 0.27 ## 6 4.60 0.52 0.8 0.89 A 0.78 0.69 Note that we see only numeric (dbl or int) and factor (fctr) variables. For now, we will require that data contains only these types, and in particular, we will coerce any categorical variables to be factors. (More on this later.) Mathematically, this data was generated from the probability model \\[ Y \\mid \\boldsymbol{X} \\sim \\text{N}(2 + 1\\cdot x_1 + 1 \\cdot \\sin(x_2) + 3 \\cdot x_3^3 + 3 \\cdot x_{4B} -2 \\cdot x_{4C}, \\sigma^2 = 0.25) \\] where \\(x_{4B}\\) is a dummy variable which takes the value 1 when \\(x_4 = \\text{B}\\) and 0 otherwise \\(x_{4C}\\) is a dummy variable which takes the value 1 when \\(x_4 = \\text{C}\\) and 0 otherwise In particular, the true mean function is \\[ \\mu(\\boldsymbol{x}) = 2 + 1\\cdot x_1 + 1 \\cdot \\sin(x_2) + 3 \\cdot x_3^3 + 3 \\cdot x_{4B} -2 \\cdot x_{4C} \\] Now, finally, let’s fit some models it R to this data! To do so, we will use one of the most important functions in R, the lm() function. Let’s specify some assumed mean functions of models that we would like to fit. Model 1 or mod_1 in R \\[ \\mu_1(\\boldsymbol{x}) = \\beta_0 + \\beta_1 x_1 \\] Model 2 or mod_2 in R \\[ \\mu_2(\\boldsymbol{x}) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 \\] Model 3 or mod_3 in R \\[ \\mu_3(\\boldsymbol{x}) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\beta_{4B} x_{4B} +\\beta_{4C} x_{4C} + \\beta_5 x_5 + \\beta_6 x_6 \\] Model 4 or mod_4 in R \\[ \\mu_4(\\boldsymbol{x}) = \\beta_0 + \\beta_1 x_1 + \\beta_2 \\sin(x_2) + \\beta_3 x_3^3 + \\beta_{4B} x_{4B} + \\beta_{4C} x_{4C} \\] Now, finally, R! mod_1 = lm(y ~ x1, data = sim_mlr_data) coef(mod_1) ## (Intercept) x1 ## 3.7834423 0.9530758 Nothing too interesting here about fitting Model 1. We see that the coef() function returns estimate of the \\(\\beta_0\\) and \\(\\beta_1\\) parameters defined above. mod_2 = lm(y ~ x1 + x2, data = sim_mlr_data) coef(mod_2) ## (Intercept) x1 x2 ## 3.8747999 0.9400654 -0.1802538 Again, Model 2 isn’t too interesting. We see that the coef() function returns estimate of the \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\beta_2\\) parameters defined above. mod_3 = lm(y ~ ., data = sim_mlr_data) coef(mod_3) ## (Intercept) x1 x2 x3 x4B x4C ## 1.71015079 0.76017877 0.77637360 3.00479841 3.06812204 -1.93068734 ## x5 x6 ## -0.12248770 -0.04797294 Now, Model 3, we see a couple interesting things. First, the formula syntax y ~ . fits a model with y as the response, and all other variables in the sim_mlr_data data frame (tibble) as features. Also note: we did not manually create the needed dummy variables! R did this for us! levels(sim_mlr_data$x4) ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; Because x4 is a factor variable, R uses the first level, A, as the reference level, and then creates dummy variables for the remaining levels. Cool! mod_4 = lm(y ~ x1 + I(sin(x2)) + I(x3 ^ 3) + x4, data = sim_mlr_data) coef(mod_4) ## (Intercept) x1 I(sin(x2)) I(x3^3) x4B x4C ## 2.3435702 0.8176247 0.9159963 3.0446314 3.0369950 -1.9421931 Our last model, mod_4 is the most interesting. It makes use of the inhibit function, I(). This allows for on-the-fly feature engineering based on available features. We’re creating new features via R’s formula syntax as we fit the model. To see why this is necessary, consider the following: lm(y ~ (x1 + x2) ^ 2, data = sim_mlr_data) ## ## Call: ## lm(formula = y ~ (x1 + x2)^2, data = sim_mlr_data) ## ## Coefficients: ## (Intercept) x1 x2 x1:x2 ## 4.1800 0.3353 -0.8259 1.3130 This created an interaction term! That means the ^ operator has different uses depending on the context. In specifying a formula, it has a particular use, in this case specifying an interaction term, and all lower order terms. However, inside of I() it will be used for exponentiation. For details, use ?I and ?formula. These are complex R topics, but it will help to start to learn them. For some additional reading on R’s formula syntax, the following two blog posts by Max Kuhn are good reads: The R Formula Method: The Good Parts The R Formula Method: The Bad Parts For the first half of this book, we will always keep the data mostly untouched, and rely heavily on the use of R’s formula syntax. If you are ever interested in what’s happening under the hood when you use the formula syntax, and you recall the linear algebra necessary to perform linear regression, the model.matrix() function will be useful. head(model.matrix(mod_4)) ## (Intercept) x1 I(sin(x2)) I(x3^3) x4B x4C ## 1 1 0.91 0.32404303 0.002744 0 0 ## 2 1 0.94 0.18885889 0.005832 1 0 ## 3 1 0.29 0.26673144 0.140608 1 0 ## 4 1 0.83 0.50553334 0.531441 1 0 ## 5 1 0.64 0.01999867 0.001728 0 0 ## 6 1 0.52 0.71735609 0.704969 0 0 Back to talking about mod_4. Recall that we had assumed that \\[ \\mu_4(\\boldsymbol{x}) = \\beta_0 + \\beta_1 x_1 + \\beta_2 \\sin(x_2) + \\beta_3 x_3^3 + \\beta_{4B} x_{4B} + \\beta_{4C} x_{4C} \\] Also recall that the true mean function is \\[ \\mu(\\boldsymbol{x}) = 2 + 1\\cdot x_1 + 1 \\cdot \\sin(x_2) + 3 \\cdot x_3^3 + 3 \\cdot x_{4B} -2 \\cdot x_{4C} \\] Because we know this, we can investigate how well our model is performing. We know the true values of the parameters, in this case \\(\\beta_0 = 2\\) \\(\\beta_1 = 1\\) \\(\\beta_2 = 1\\) \\(\\beta_3 = 3\\) \\(\\beta_{4B} = 3\\) \\(\\beta_{4C} = -2\\) \\(\\beta_5 = 0\\) (\\(x_5\\) is not used in the true mean function.) \\(\\beta_6 = 0\\) (\\(x_6\\) is not used in the true mean function.) We also have the estimated coefficients from mod_4. coef(mod_4) ## (Intercept) x1 I(sin(x2)) I(x3^3) x4B x4C ## 2.3435702 0.8176247 0.9159963 3.0446314 3.0369950 -1.9421931 \\(\\hat{\\beta}_0 = 2.34\\) \\(\\hat{\\beta}_1 = 0.82\\) \\(\\hat{\\beta}_2 = 0.92\\) \\(\\hat{\\beta}_3 = 3.04\\) \\(\\hat{\\beta}_{4B} = 3.04\\) \\(\\hat{\\beta}_{4C} = -1.94\\) \\(\\hat{\\beta}_5 = 0\\) (We assumed \\(x_5\\) is not used in the true mean function.) \\(\\hat{\\beta}_6 = 0\\) (We assumed \\(x_6\\) is not used in the true mean function.) Our estimated regression (mean) function is then \\[ \\hat{\\mu}_4(\\boldsymbol{x}) = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\hat{\\beta}_2 \\sin(x_2) + \\hat{\\beta}_3 x_3^3 + \\hat{\\beta}_{4B} x_{4B} + \\hat{\\beta}_{4C} x_{4C} \\] Perfect? No. Pretty good? Maybe. However, in reality, this is not a check that we can perform! We still need an evaluation strategy that doesn’t depend on knowing the true model! Note that the other models are “bad” in this case because they are either missing features (mod_1 and mod_2) or the are both missing features and contain unnecessary features (mod_3). 6.7 The predict() Function We stated previously that fitting a linear regression model means that we are learning the regression (mean) function. Now that we fit and stored some models, how do we access these estimated regression (mean) functions? The predict() function! The predict() function will be the workhorse of STAT 432. Let’s see how to use it with models fit using the lm() function. set.seed(3) new_obs = gen_mlr_data(sample_size = 1) new_obs ## # A tibble: 1 x 7 ## y x1 x2 x3 x4 x5 x6 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.751 0.17 0.81 0.38 C 0.6 0.6 Suppose we wanted to estimate the mean of \\(Y\\) when \\(x_1 = 0.17\\) \\(x_2 = 0.81\\) \\(x_3 = 0.38\\) \\(x_4 = \\text{C}\\) \\(x_5 = 0.38\\) \\(x_6 = 0.38\\) In other words, we want to estimate \\[ \\mathbb{E}[Y \\mid \\boldsymbol{X} = \\texttt{new_obs}] = \\mathbb{E}[Y \\mid X_1 = 0.17, X_2 = 0.81, X_3 = 0.38, X_4 = \\text{C}, X_5 = 0.6, X_6 = 0.6] \\] The predict() function to the rescue! predict(mod_1, new_obs) ## 1 ## 3.945465 What’s being returned here? \\[ \\hat{\\mu}_1(\\texttt{new_obs}) = \\hat{\\mathbb{E}}[Y \\mid \\boldsymbol{X} = \\texttt{new_obs}] = 3.9454652 \\] The predict function is essentially the estimated regression (mean) function! Supply a different model, then you get that estimated regression (mean) function. predict(mod_4, new_obs) ## 1 ## 1.370883 What’s being returned here? \\[ \\hat{\\mu}_4(\\texttt{new_obs}) = \\hat{\\mathbb{E}}[Y \\mid \\boldsymbol{X} = \\texttt{new_obs}] = 1.3708827 \\] We could compare these two estimates of the conditional mean of \\(Y\\) to the true value of y observed in the observation. More on that in the next section. If given an entire dataset, instead of a single observation, predict() returns the estimated conditional mean of each observation. set.seed(9) some_more_data = gen_mlr_data(sample_size = 10) predict(mod_4, some_more_data) ## 1 2 3 4 5 6 7 8 ## 7.8896349 5.4061018 1.3788387 0.8560024 6.6246872 8.2203544 3.2140060 3.5738889 ## 9 10 ## 5.9928135 8.4908895 Neat! A warning: Do not name the second argument to the predict function. This will cause issues because sometimes the name of that argument is newdata, as it is here, but sometimes it is data. If you use the wrong name, bad things will happen. It is safer to simply never name this argument. (However, in general, arguments after the first should be named. The predict() function is the exception.) 6.8 Data Splitting (Note: Many readers will have possibly seen some machine learning previously. For now, please pretend that you have never heard of or seen cross-validation. Cross-validation will clutter the initial introduction of many concepts. We will return to and formalize it later.) OK. So now we can fit models, and make predictions (create estimates of the conditional mean of \\(Y\\) given values of the features), how do we evaluate how well our models perform, without knowing the true model! First, let’s state a somewhat specific goal. We would like to train models that generalize well, that is, perform well on “new” or “unseen” data that was not used to train the model. To accomplish this goal, we’ll just “create” a dataset that isn’t used to train the model! To create it, we will just split it off. (We’ll actually do so twice.) First, denote the entire available data as \\(\\mathcal{D}\\). \\[ \\mathcal{D} = \\{ (x_i, y_i) \\in \\mathbb{R}^p \\times \\mathbb{R}, \\ i = 1, 2, \\ldots n \\} \\] We first split this data into a train and test set. We will discuss these two dataset ad nauseam, but let’s set two rules right now. You can do whatever you would like with the training data. However, it is best used to train, evaluate, and select models. Do not, ever, for any reason, fit a model using test data! Additionally, you should not select models using test data. In STAT 432, we will only use test data to provide a final estimate of the generalization error of a chosen model. (Much more on this along the way.) Again, Do not, ever, for any reason, fit a model using test data! I repeat: Do not, ever, for any reason, fit a model using test data! (You’ve been warned.) To perform this split, we will randomly select some observations for the train (trn) set, the remainder will be used for the test (tst) set. \\[ \\mathcal{D} = \\mathcal{D}_{\\texttt{trn}} \\cup \\mathcal{D}_{\\texttt{tst}} \\] As a general guiding heuristic, use 80% of the data for training, 20% for testing. In addition to the train-test split, we will further split the train data into estimation and validation sets. These are somewhat confusing terms, developed for STAT 432, but hear us out. To perform this split, we will randomly select some observations (from the train set) for the estimation (est) set, the remainder will be used for the validation (val) set. \\[ \\mathcal{D}_{\\texttt{trn}} = \\mathcal{D}_{\\texttt{est}} \\cup \\mathcal{D}_{\\texttt{val}} \\] Again, use 80% of the data for estimation, 20% for validation. The need for this second split might not become super clear until later on, but the general idea is this: Fit a bunch of candidate models to the estimation data. (Think of this as the data to estimate the model parameters. That’s how we chose the name.) Using these candidate models, evaluate how well they perform using the validation data. After evaluating and picking a single model, re-fit this model to the entire training dataset. Provide an estimate of how well this model performs using the test data. Now that we have data for estimation, and validation, we need some metrics for evaluating these models. 6.9 Regression Metrics If our goal is to “predict” then we want small errors. In general there are two types of errors we consider: Squared Errors: \\((y_i - \\hat{\\mu}(\\boldsymbol{x})) ^2\\) Absolute Errors: \\(|y_i - \\hat{\\mu}(\\boldsymbol{x})|\\) In both cases, we will want to consider the average errors made. We define two metrics. Root Mean Square Error (RMSE) \\[ \\text{rmse}\\left(\\hat{f}_{\\texttt{set_f}}, \\mathcal{D}_{\\texttt{set_D}} \\right) = \\sqrt{\\frac{1}{n_{\\texttt{set_D}}}\\displaystyle\\sum_{i \\in {\\texttt{set_D}}}^{}\\left(y_i - \\hat{f}_{\\texttt{set_f}}({x}_i)\\right)^2} \\] Mean Absolute Error (MAE) \\[ \\text{mae}\\left(\\hat{f}_{\\texttt{set_f}}, \\mathcal{D}_{\\texttt{set_D}} \\right) = \\frac{1}{n_{\\texttt{set_D}}}\\displaystyle\\sum_{i \\in {\\texttt{set_D}}}^{}\\left|y_i - \\hat{f}_{\\texttt{set_f}}({x}_i)\\right| \\] \\(\\hat{f}_{\\texttt{set_f}}\\) is a function \\(f\\) estimated using a model fit to some dataset \\(\\texttt{set_f}\\). The \\((x_i, y_i)\\) are data from dataset \\(\\mathcal{D}_{\\texttt{set_D}}\\). For both, smaller is better. (Less error on average.) In both, we note both the data that the model was fit to, as well as the data the model is evaluated on. Depending on the data used for these different sets, we “define” different metrics. For example, for RMSE, we have: Train RMSE: Evaluate a model fit to estimation data, using estimation data. \\[ \\text{RMSE}_{\\texttt{trn}} = \\text{rmse}\\left(\\hat{f}_{\\texttt{est}}, \\mathcal{D}_{\\texttt{est}}\\right) = \\sqrt{\\frac{1}{n_{\\texttt{est}}}\\displaystyle\\sum_{i \\in {\\texttt{est}}}^{}\\left(y_i - \\hat{f}_{\\texttt{est}}({x}_i)\\right)^2} \\] Validation RMSE: Evaluate a model fit to estimation data, using validation data. \\[ \\text{RMSE}_{\\texttt{val}} = \\text{rmse}\\left(\\hat{f}_{\\texttt{est}}, \\mathcal{D}_{\\texttt{val}}\\right) = \\sqrt{\\frac{1}{n_{\\texttt{val}}}\\displaystyle\\sum_{i \\in {\\texttt{val}}}^{}\\left(y_i - \\hat{f}_{\\texttt{est}}({x}_i)\\right)^2} \\] Test RMSE: Evaluate a model fit to training data, using test data. \\[ \\text{RMSE}_{\\texttt{tst}} = \\text{rmse}\\left(\\hat{f}_{\\texttt{trn}}, \\mathcal{D}_{\\texttt{tst}}\\right) = \\sqrt{\\frac{1}{n_{\\texttt{tst}}}\\displaystyle\\sum_{i \\in {\\texttt{tst}}}^{}\\left(y_i - \\hat{f}_{\\texttt{trn}}({x}_i)\\right)^2} \\] For the rest of this chapter, we will largely ignore train error. It’s a bit confusing, since it doesn’t use the full training data! However, think of training error this way: training error evaluates how well a model performs on the data used to fit the model. Let’s return to the sim_mlr_data data and apply these splits and metrics to this data. # test-train split mlr_trn_idx = sample(nrow(sim_mlr_data), size = 0.8 * nrow(sim_mlr_data)) mlr_trn = sim_mlr_data[mlr_trn_idx, ] mlr_tst = sim_mlr_data[-mlr_trn_idx, ] Here we randomly select 80% of the rows of the full data, and store these indices as mlr_trn_idx. We then create the mlr_trn and mlr_tst datasets by either selecting or anti-selecting these rows from the original dataset. # estimation-validation split mlr_est_idx = sample(nrow(mlr_trn), size = 0.8 * nrow(mlr_trn)) mlr_est = mlr_trn[mlr_est_idx, ] mlr_val = mlr_trn[-mlr_est_idx, ] We then repeat the process from above within the train data. Now, let’s compare mod_3 and mod_4. To do so, we first fit both models to the estimation data. mod_3_est = lm(y ~ ., data = mlr_est) mod_4_est = lm(y ~ x1 + I(sin(x2)) + I(x3 ^ 3) + x4, data = mlr_est) We then calculate the validation error for both. Because we will do it so often, we go ahead and write a function to calculate RMSE, given vectors of the actual values (from the data used to evaluate) and the predictions from the model. calc_rmse = function(actual, predicted) { sqrt(mean((actual - predicted) ^ 2)) } # calculate validation RMSE, model 3 calc_rmse(actual = mlr_val$y, predicted = predict(mod_3_est, mlr_val)) ## [1] 0.5788282 # calculate validation RMSE, model 4 calc_rmse(actual = mlr_val$y, predicted = predict(mod_4_est, mlr_val)) ## [1] 0.5452852 Here we see that mod_4_est achieves a lower validation error, so we move forward with this model. We then refit to the full train data, then evaluate on test. mod_4_trn = lm(y ~ x1 + I(sin(x2)) + I(x3 ^ 3) + x4, data = mlr_trn) # calculate test RMSE, model 4 calc_rmse(actual = mlr_tst$y, predicted = predict(mod_4_trn, mlr_tst)) ## [1] 0.538057 We ignore the validation metrics. (we already used them for selecting a model.) This test RMSE is our estimate of how well our selected model will perform on unseen data, on average (in a squared error sense). Note that for selecting a model there is no difference between MSE and RMSE, but for the sake of understanding, RMSE has preferential units, the same units as the response variables. (Whereas MSE has units squared.) We will always report RMSE. 6.9.1 Graphical Evaluation In addition to numeric evaluations, we can evaluate a regression model graphical, in particular with a predicted versus actual plot. plot( x = mlr_tst$y, y = predict(mod_4_trn, mlr_tst), pch = 20, col = &quot;darkgrey&quot;, xlim = c(-1, 10), ylim = c(-1, 10), main = &quot;Predicted vs Actual, Model 4, Test Data&quot;, xlab = &quot;Actual&quot;, ylab = &quot;Predicted&quot; ) abline(a = 0, b = 1, lwd = 2) grid() The closer to the line the better. Also, the less of a pattern the better. In other words, this plot will help diagnose if our model is making similar sized errors for all predictions, or if there are systematic differences. This might get you thinking about “checking the assumptions” of a linear model. Assessing things like: normality, constant variance, etc. Note that while these are nice things to have, we aren’t really concerned with these things. If we care how well our model predicts, then we will directly evaluate how well it predicts. Least squares is least squares. It minimizes errors. It doesn’t care about model assumptions. 6.10 Example: “Simple” Simulated Data Let’s return to our initial dataset with a single feature \\(x\\). This time we’ll generate more data, and then split it. cubic_mean = function(x) { 1 - 2 * x - 3 * x ^ 2 + 5 * x ^ 3 } gen_slr_data = function(sample_size = 100, mu) { x = runif(n = sample_size, min = -1, max = 1) y = mu(x) + rnorm(n = sample_size) tibble(x, y) } set.seed(3) sim_slr_data = gen_slr_data(sample_size = 100, mu = cubic_mean) # test-train split slr_trn_idx = sample(nrow(sim_slr_data), size = 0.8 * nrow(sim_slr_data)) slr_trn = sim_slr_data[slr_trn_idx, ] slr_tst = sim_slr_data[-slr_trn_idx, ] # estimation-validation split slr_est_idx = sample(nrow(slr_trn), size = 0.8 * nrow(slr_trn)) slr_est = slr_trn[slr_est_idx, ] slr_val = slr_trn[-slr_est_idx, ] # check data head(slr_trn, n = 10) ## # A tibble: 10 x 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0.573 -1.18 ## 2 0.807 0.576 ## 3 0.272 -0.973 ## 4 -0.813 -1.78 ## 5 -0.161 0.833 ## 6 0.736 1.07 ## 7 -0.242 2.97 ## 8 0.520 -1.64 ## 9 -0.664 0.269 ## 10 -0.777 -2.02 This time let’s evaluate nine different models. Polynomial models from degree 1 to 9. We fit each model to the estimation data, and store the results in a list. poly_mod_est_list = list( poly_mod_1_est = lm(y ~ poly(x, degree = 1), data = slr_est), poly_mod_2_est = lm(y ~ poly(x, degree = 2), data = slr_est), poly_mod_3_est = lm(y ~ poly(x, degree = 3), data = slr_est), poly_mod_4_est = lm(y ~ poly(x, degree = 4), data = slr_est), poly_mod_5_est = lm(y ~ poly(x, degree = 5), data = slr_est), poly_mod_6_est = lm(y ~ poly(x, degree = 6), data = slr_est), poly_mod_7_est = lm(y ~ poly(x, degree = 7), data = slr_est), poly_mod_8_est = lm(y ~ poly(x, degree = 8), data = slr_est), poly_mod_9_est = lm(y ~ poly(x, degree = 9), data = slr_est) ) So, for example, to access the third model, we would use poly_mod_est_list[[3]] ## ## Call: ## lm(formula = y ~ poly(x, degree = 3), data = slr_est) ## ## Coefficients: ## (Intercept) poly(x, degree = 3)1 poly(x, degree = 3)2 ## -0.2058 5.3030 -7.4306 ## poly(x, degree = 3)3 ## 6.7638 But let’s back up. That code was terrible to write. Too much repeated code. Consider the following code poly_mod_est_list = map(1:9, ~ lm(y ~ poly(x, degree = .x), data = slr_est)) This accomplishes the same task, but is much cleaner! poly_mod_est_list[[3]] ## ## Call: ## lm(formula = y ~ poly(x, degree = .x), data = slr_est) ## ## Coefficients: ## (Intercept) poly(x, degree = .x)1 poly(x, degree = .x)2 ## -0.2058 5.3030 -7.4306 ## poly(x, degree = .x)3 ## 6.7638 Here we are using the map() function from the purrr package. The ~ here is used to create a function in place. We’ll consider another way to make it a bit clearer, that is, without writing the function within map(). fit_poly_mod_to_est_data = function(d) { lm(y ~ poly(x, degree = d), data = slr_est) } poly_mod_est_list = map(1:9, fit_poly_mod_to_est_data) Again, the same thing. poly_mod_est_list[[3]] ## ## Call: ## lm(formula = y ~ poly(x, degree = d), data = slr_est) ## ## Coefficients: ## (Intercept) poly(x, degree = d)1 poly(x, degree = d)2 ## -0.2058 5.3030 -7.4306 ## poly(x, degree = d)3 ## 6.7638 We’ll continue to use this map() function throughout. We’ll explain more and more as we go. Note that the map() function returns a list. The following makes predictions for each of the models, once using the estimation data, once using validation. poly_mod_est_pred = map(poly_mod_est_list, predict, slr_est) poly_mod_val_pred = map(poly_mod_est_list, predict, slr_val) If instead we wanted to return a numeric vector, we would use, map_dbl(). Let’s use this to calculate train and validation RMSE. # calculate train RMSE slr_est_rmse = map_dbl(poly_mod_est_pred, calc_rmse, actual = slr_est$y) # calculate validation RMSE slr_val_rmse = map_dbl(poly_mod_val_pred, calc_rmse, actual = slr_val$y) slr_est_rmse ## [1] 1.5748180 1.2717458 0.9500069 0.9480786 0.9302359 0.9187948 0.9151668 ## [8] 0.9120942 0.9117093 Note that training error goes down as degree goes up. More on this next chapter. slr_val_rmse ## [1] 1.6584930 1.2791685 0.9574010 0.9729928 1.0104449 1.0505615 1.0617693 ## [8] 1.0953461 1.0968283 which.min(slr_val_rmse) ## [1] 3 The model with polynomial degree 3 has the lowest validation error, so we move forward with this model. We re-fit to the full train dataset, then evaluate on the test set one last time. poly_mod_3_trn = lm(y ~ poly(x, degree = 3), data = slr_trn) calc_rmse(actual = slr_tst$y, predicted = predict(poly_mod_3_trn, slr_tst)) ## [1] 0.7198306 Note: There are hints here that this process is a bit unstable. See if you can figure out why. Hint: See what happens when you change the seed to generate or split the data. We’ll return to this issue when we introduce cross-validation, but for now, we’ll pretend we didn’t notice. We’ll round out this chapter with three “real” data examples. 6.11 Example: Diamonds Data For this example, we use (a subset of) the diamonds data from the ggplot2 package. # load (subset of) data set.seed(42) dmnd = ggplot2::diamonds[sample(nrow(diamonds), size = 5000), ] # data prep dmnd = dmnd %&gt;% mutate(cut = factor(cut, ordered = FALSE), color = factor(color, ordered = FALSE), clarity = factor(clarity, ordered = FALSE)) %&gt;% select(-price, everything()) # test-train split dmnd_trn_idx = sample(nrow(dmnd), size = 0.8 * nrow(dmnd)) dmnd_trn = dmnd[dmnd_trn_idx, ] dmnd_tst = dmnd[-dmnd_trn_idx, ] # estimation-validation split dmnd_est_idx = sample(nrow(dmnd_trn), size = 0.8 * nrow(dmnd_trn)) dmnd_est = dmnd_trn[dmnd_est_idx, ] dmnd_val = dmnd_trn[-dmnd_est_idx, ] The code above loads the data, then performs a test-train split, then additionally an estimation-validation split. We then look at the train data. That is we do not even look at the test data. # check data head(dmnd_trn, n = 10) ## # A tibble: 10 x 10 ## carat cut color clarity depth table x y z price ## &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 0.5 Premium H SI1 59 59 5.22 5.18 3.07 1156 ## 2 1.01 Ideal G SI2 63.2 57 6.33 6.28 3.99 4038 ## 3 0.62 Very Good D SI1 61.3 58 5.47 5.49 3.36 1949 ## 4 0.41 Ideal D VS2 62.4 54 4.78 4.74 2.97 1076 ## 5 0.31 Ideal G IF 61.6 54 4.36 4.4 2.7 853 ## 6 1.08 Ideal I SI1 62.6 53.9 6.51 6.56 4.09 5049 ## 7 0.52 Very Good G VS2 62.4 60 5.14 5.18 3.22 1423 ## 8 1.01 Premium F SI2 60.9 60 6.45 6.42 3.91 3297 ## 9 0.570 Ideal H VS1 61.7 54 5.33 5.36 3.3 1554 ## 10 0.34 Ideal H VS2 62.5 54 4.54 4.49 2.82 689 Our goal here will be to build a model to predict the price of a diamond given it’s characteristics. Let’s create a few EDA plots. Note that these plots do not contain the test data. If they did, we would be using the test data to influence model building and selection, a big no-no. Let’s consider four possible models, each of which we fit to the estimation data. dmnd_mod_1_est = lm(price ~ carat, data = dmnd_est) dmnd_mod_2_est = lm(price ~ carat + x + y + z, data = dmnd_est) dmnd_mod_3_est = lm(price ~ poly(carat, degree = 2) + x + y + z, data = dmnd_est) dmnd_mod_4_est = lm(price ~ poly(carat, degree = 2) + . - carat, data = dmnd_est) Now, let’s calculate the validation RMSE of each. dmnd_mod_list = list( dmnd_mod_1_est, dmnd_mod_2_est, dmnd_mod_3_est, dmnd_mod_4_est ) dmnd_mod_val_pred = map(dmnd_mod_list, predict, dmnd_val) map_dbl(dmnd_mod_val_pred, calc_rmse, actual = dmnd_val$price) ## [1] 1583.558 1517.080 1634.396 1350.659 It looks like model dmnd_mod_4_est achieves the lowest validation error. We re-fit this model, then report the test RMSE. dmnd_mod_4_trn = lm(price ~ poly(carat, degree = 2) + . - carat, data = dmnd_trn) calc_rmse(actual = dmnd_tst$price, predicted = predict(dmnd_mod_4_trn, dmnd_tst)) ## [1] 1094.916 So, on average, this model is “wrong” by about $1000 dollars. However, less-so when it is a low cost diamond, more so with high priced diamonds, as we can see in the plot below. plot( x = dmnd_tst$price, y = predict(dmnd_mod_4_trn, dmnd_tst), pch = 20, col = &quot;darkgrey&quot;, xlim = c(0, 25000), ylim = c(0, 25000), main = &quot;Diamonds: Predicted vs Actual, Model 4, Test Data&quot;, xlab = &quot;Actual&quot;, ylab = &quot;Predicted&quot; ) abline(a = 0, b = 1, lwd = 2) grid() Some things to consider: Could you use the predicted versus actual plot to assist in selecting a model with the validation data? Note that the model we have chosen is not necessarily the “best” model. It is simply the model with the lowest validation RMSE. This is currently a very simplistic analysis. Can you improve this model? Would a log transform of price help? 6.12 Example: Credit Card Data Suppose you work for a small local bank, perhaps a credit union, that has a credit card product offering. For years, you relied on credit agencies to provide a rating of your customer’s credit, however, this costs your bank money. One day, you realize that it might be possible to reverse engineer your customers’ (and thus potential customers) credit rating based on the credit ratings that you already have already purchase, as well as the demographic and credit card information that you already have, such as age, education level, credit limit, etc. (We make no comment on the legality or ethics of this idea. Consider these before using at your own risk.) So long as you can estimate customers’ credit rating with a reasonable error, you could stop buying the ratings from an agency. Effectively, you will have created your own rating. # load data, coerce to tibble crdt = as_tibble(ISLR::Credit) To perform this analysis, we will use the Credit data form the ISLR package. Note: this is not real data. It has been simulated. # data prep crdt = crdt %&gt;% select(-ID) %&gt;% select(-Rating, everything()) We remove the ID variable as it should have no predictive power. We also move the Rating variable to the last column with a clever dplyr trick. This is in no way necessary, but is useful in creating some plots. # test-train split set.seed(1) crdt_trn_idx = sample(nrow(crdt), size = 0.8 * nrow(crdt)) crdt_trn = crdt[crdt_trn_idx, ] crdt_tst = crdt[-crdt_trn_idx, ] # estimation-validation split crdt_est_idx = sample(nrow(crdt_trn), size = 0.8 * nrow(crdt_trn)) crdt_est = crdt_trn[crdt_est_idx, ] crdt_val = crdt_trn[-crdt_est_idx, ] After train-test and estimation-validation splitting the data, we look at the train data. # check data head(crdt_trn, n = 10) ## # A tibble: 10 x 11 ## Income Limit Cards Age Education Gender Student Married Ethnicity Balance ## &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 183. 13913 4 98 17 &quot; Mal… No Yes Caucasian 1999 ## 2 35.7 2880 2 35 15 &quot; Mal… No No African … 0 ## 3 123. 8376 2 89 17 &quot; Mal… Yes No African … 1259 ## 4 20.8 2672 1 70 18 &quot;Fema… No No African … 0 ## 5 39.1 5565 4 48 18 &quot;Fema… No Yes Caucasian 772 ## 6 36.5 3806 2 52 13 &quot; Mal… No No African … 188 ## 7 45.1 3762 3 80 8 &quot; Mal… No Yes Caucasian 70 ## 8 43.5 2906 4 69 11 &quot; Mal… No No Caucasian 0 ## 9 23.1 3476 2 50 15 &quot;Fema… No No Caucasian 209 ## 10 53.2 4943 2 46 16 &quot;Fema… No Yes Asian 382 ## # … with 1 more variable: Rating &lt;int&gt; To get a better “look” at the data, consider running the following: skimr::skim(crdt_trn) str(crdt_trn) View(crdt_trn) We also create a pairs plot. We immediately notice three variables that have a strong correlation with Rating: Income, Limit, and Balance. Based on this, we evaluate five candidate models. crdt_mod_0_est = lm(Rating ~ 1, data = crdt_est) crdt_mod_1_est = lm(Rating ~ Limit, data = crdt_est) crdt_mod_2_est = lm(Rating ~ Limit + Income + Balance, data = crdt_est) crdt_mod_3_est = lm(Rating ~ ., data = crdt_est) crdt_mod_4_est = step(lm(Rating ~ . ^ 2, data = crdt_est), trace = FALSE) crdt_mod_list = list( crdt_mod_0_est, crdt_mod_1_est, crdt_mod_2_est, crdt_mod_3_est, crdt_mod_4_est ) crdt_mod_val_pred = map(crdt_mod_list, predict, crdt_val) map_dbl(crdt_mod_val_pred, calc_rmse, actual = crdt_val$Rating) ## [1] 140.080591 12.244099 12.333767 9.890607 11.575484 From these results, it appears that the additive model, including all terms performs best. We move forward with this model. final_credit_model = lm(Rating ~ ., data = crdt_trn) sqrt(mean((predict(final_credit_model, crdt_tst) - crdt_tst$Rating) ^ 2)) ## [1] 10.47727 It seems that on average, this model errors by about 10 credit points. range(crdt_trn$Rating) ## [1] 93 982 sd(crdt_trn$Rating) ## [1] 157.5897 Given the range of possible ratings, this seem pretty good! What do you think? plot( x = crdt_tst$Rating, y = predict(final_credit_model, crdt_tst), pch = 20, col = &quot;darkgrey&quot;, # xlim = c(0, 25000), ylim = c(0, 25000), main = &quot;Credit: Predicted vs Actual, Test Data&quot;, xlab = &quot;Actual&quot;, ylab = &quot;Predicted&quot; ) abline(a = 0, b = 1, lwd = 2) grid() The predicted versus actual plot almost looks too good to be true! Wow! (Oh, wait. This was simulated data…) In summary, if this data were real, we might have an interesting result! Do note, that both this example and the previous should not be considered data analyses, but instead, examples that reinforce how to use the validation and test sets. As part of a true analysis, we will need to be much more careful about some of our decision. More on this later! Up next: nonparametric regression methods. 6.13 Source R Markdown: 06-linear-regression.Rmd "],
["nonparametric-regression.html", "Chapter 7 Nonparametric Regression 7.1 Reading 7.2 Mathematical Setup 7.3 k-Nearest Neighbors 7.4 Decision Trees 7.5 Example: Credit Card Data 7.6 Source", " Chapter 7 Nonparametric Regression In this chapter, we will continue to explore models for making predictions, but now we will introduce nonparametric models that will contrast the parametric models that we have used previously. Specifically, we will discuss: How to use k-nearest neighbors for regression through the use of the knnreg() function from the caret package How to use decision trees for regression through the use of the rpart() function from the rpart package. How “making predictions” can be thought of as estimating the regression function, that is, the conditional mean of the response given values of the features. What is the difference between parametric and nonparametric methods? How do these nonparametric methods deal with categorical variables and interactions. We will also hint at, but delay one more chapter discussion of: What is model flexibility? What are tuning parameters? (What are model parameters?) What is overfitting? How do we avoid it? 7.1 Reading Currently no additional reading for this chapter. 7.2 Mathematical Setup Let’s return to the setup we defined in the previous chapter. Consider a random variable \\(Y\\) which represents a response variable, and \\(p\\) feature variables \\(\\boldsymbol{X} = (X_1, X_2, \\ldots, X_p)\\). We assume that the response variable \\(Y\\) is some function of the features, plus some random noise. \\[ Y = f(\\boldsymbol{X}) + \\epsilon \\] Our goal will is to find some \\(f\\) such that \\(f(\\boldsymbol{X})\\) is close to \\(Y\\). More specifically we want to minimize the risk under squared error loss. \\[ \\mathbb{E}_{\\boldsymbol{X}, Y} \\left[ (Y - f(\\boldsymbol{X})) ^ 2 \\right] = \\mathbb{E}_{\\boldsymbol{X}} \\mathbb{E}_{Y \\mid \\boldsymbol{X}} \\left[ ( Y - f(\\boldsymbol{X}) ) ^ 2 \\mid \\boldsymbol{X} = \\boldsymbol{x} \\right] \\] We saw last chapter that this risk is minimized by the conditional mean of \\(Y\\) given \\(\\boldsymbol{X}\\), \\[ \\mu(\\boldsymbol{x}) \\triangleq \\mathbb{E}[Y \\mid \\boldsymbol{X} = \\boldsymbol{x}] \\] which we called the regression function. Our goal then is to estimate this regression function. Let’s return to the example from last chapter where we know the true probability model. \\[ Y = 1 - 2x - 3x ^ 2 + 5x ^ 3 + \\epsilon \\] where \\(\\epsilon \\sim \\text{N}(0, \\sigma^2)\\). Recall that this implies that the regression function is \\[ \\mu(x) = \\mathbb{E}[Y \\mid \\boldsymbol{X} = \\boldsymbol{x}] = 1 - 2x - 3x ^ 2 + 5x ^ 3 \\] Let’s also return to pretending that we do not actually know this information, but instead have some data, \\((x_i, y_i)\\) for \\(i = 1, 2, \\ldots, n\\). x y -0.4689827 0.7174461 -0.2557522 1.2154439 0.1457067 1.6041985 0.8164156 0.9096322 -0.5966361 0.6573128 0.7967794 0.9500528 0.8893505 1.1477361 0.3215956 0.2874057 0.2582281 -1.6197576 -0.8764275 -2.2977242 -0.5880509 0.0658105 -0.6468865 -0.4708965 0.3740457 -1.3769103 -0.2317926 0.7619832 0.5396828 0.2507367 -0.0046015 2.3678186 0.4352370 -0.1293181 0.9838122 1.2774803 -0.2399296 1.1842963 0.5548904 -1.5562874 0.8694105 -0.1356129 -0.5757150 -0.1913002 0.3033475 0.1975021 -0.7488898 -0.1847245 -0.4655587 1.5395212 -0.2277718 1.0762960 -0.9732193 -4.7573427 -0.2352241 1.9363453 0.7393817 0.4588894 -0.3193020 0.4812168 (We simulated a bit more data than last time to make the “pattern” clearer to recognize.) Recall that when we used a linear model, we first need to make an assumption about the form of the regression function. For example, we could assume that \\[ \\mu(x) = \\mathbb{E}[Y \\mid \\boldsymbol{X} = \\boldsymbol{x}] = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\beta_3 x^3 \\] which is fit in R using the lm() function lm(y ~ x + I(x ^ 2) + I(x ^ 3), data = sim_slr_data) ## ## Call: ## lm(formula = y ~ x + I(x^2) + I(x^3), data = sim_slr_data) ## ## Coefficients: ## (Intercept) x I(x^2) I(x^3) ## 0.8397 -2.7257 -2.3752 6.0906 Notice that what is returned are (maximum likelihood or least squares) estimates of the unknown \\(\\beta\\) coefficients. That is, the “learning” that takes place with a linear models is “learning” the values of the coefficients. For this reason, we call linear regression models parametric models. They have unknown model parameters, in this case the \\(\\beta\\) coefficients that must be learned from the data. The form of the regression function is assumed. What if we don’t want to make an assumption about the form of the regression function? While in this case, you might look at the plot and arrive at a reasonable guess of assuming a third order polynomial, what if it isn’t so clear? What if you have 100 features? Making strong assumptions might not work well. Enter nonparametric models. We will consider two examples: k-nearest neighbors and decision trees. 7.3 k-Nearest Neighbors We’ll start with k-nearest neighbors which is possibly a more intuitive procedure than linear models. If our goal is to estimate the mean function, \\[ \\mu(x) = \\mathbb{E}[Y \\mid \\boldsymbol{X} = \\boldsymbol{x}] \\] the most natural approach would be to use \\[ \\text{average}(\\{ y_i : x_i = x \\}) \\] that is, to estimate the conditional mean at \\(x\\), average the \\(y_i\\) values for each data point where \\(x_i = x\\). While this sounds nice, it has an obvious flaw. For most values of \\(x\\) there will not be any \\(x_i\\) in the data where \\(x_i = x\\)! So what’s the next best thing? Pick values of \\(x_i\\) that are “close” to \\(x\\). \\[ \\text{average}( \\{ y_i : x_i \\text{ equal to (or very close to) x} \\} ) \\] This is the main idea behind many nonparametric approaches. In the case of k-nearest neighbors we use \\[ \\hat{\\mu}_k(x) = \\frac{1}{k} \\sum_{ \\{i \\ : \\ x_i \\in \\mathcal{N}_k(x, \\mathcal{D}) \\} } y_i \\] as our estimate of the regression function at \\(x\\). While this looks complicated, it is actually very simple. Here, we are using an average of the \\(y_i\\) values of for the \\(k\\) nearest neighbors to \\(x\\). The \\(k\\) “nearest” neighbors are the \\(k\\) data points \\((x_i, y_i)\\) that have \\(x_i\\) values that are nearest to \\(x\\). We can define “nearest” using any distance we like, but unless otherwise noted, we are referring to euclidean distance. (The usual distance when you hear distance.) We are using the notation \\(\\{i \\ : \\ x_i \\in \\mathcal{N}_k(x, \\mathcal{D}) \\}\\) to define the observations that have \\(x_i\\) values that are nearest to the value \\(x\\) in a dataset \\(\\mathcal{D}\\), in other words, the \\(k\\) nearest neighbors. The plots below begin to illustrate this idea. In the left plot, to estimate the mean of \\(Y\\) at \\(x = -0.5\\) we use the three nearest neighbors, which are highlighted with green. Our estimate is the average of the \\(y_i\\) values of these three points indicated by the black x. In the middle plot, to estimate the mean of \\(Y\\) at \\(x = 0\\) we use the five nearest neighbors, which are highlighted with green. Our estimate is the average of the \\(y_i\\) values of these five points indicated by the black x. In the right plot, to estimate the mean of \\(Y\\) at \\(x = 0.75\\) we use the nine nearest neighbors, which are highlighted with green. Our estimate is the average of the \\(y_i\\) values of these nine points indicated by the black x. You might begin to notice a bit of an issue here. We have to do a new calculation each time we want to estimate the regression function at a different value of \\(x\\)! For this reason, k-nearest neighbors is often said to be “fast to train” and “slow to predict.” Training, is instant. You just memorize the data! Prediction involves finding the distance between the \\(x\\) considered and all \\(x_i\\) in the data! (For this reason, KNN is often not used in practice, but it is very useful learning tool.) So, how then, do we choose the value of the tuning parameter \\(k\\)? We validate! First, let’s take a look at what happens with this data if we consider three different values of \\(k\\). For each plot, the black dashed curve is the true mean function. In the left plot we use \\(k = 25\\). The red “curve” is the estimate of the mean function for each \\(x\\) shown in the plot. In the left plot we use \\(k = 5\\). The blue “curve” is the estimate of the mean function for each \\(x\\) shown in the plot. In the left plot we use \\(k = 1\\). The green “curve” is the estimate of the mean function for each \\(x\\) shown in the plot. Some things to notice here: The left plot with \\(k = 25\\) is performing poorly. The estimated “curve” does not “move” enough. This is an example of an inflexible model. The right plot with \\(k = 1\\) might not perform too well. The estimated “curve” seems to “move” too much. (Notice, that it goes through each point. We’ve fit to the noise.) This is an example of a flexible model. While the middle plot with \\(k = 5\\) is not “perfect” it seems to roughly capture the “motion” of the true regression function. We can begin to see that if we generated new data, this estimated regression function would perform better than the other two. But remember, in practice, we won’t know the true regression function, so we will need to determine how our model performs using only the available data! This \\(k\\), the number of neighbors, is an example of a tuning parameter. Instead of being learned from the data, like model parameters such as the \\(\\beta\\) coefficients in linear regression, a tuning parameter tells us how to learn from data. It is user-specified. To determine the value of \\(k\\) that should be used, many models are fit to the estimation data, then evaluated on the validation. Using the information from the validation data, a value of \\(k\\) is chosen. (More on this in a bit.) This tuning parameter \\(k\\) also defines the flexibility of the model. In KNN, a small value of \\(k\\) is a flexible model, while a large value of \\(k\\) is inflexible. (Many text use the term complex instead of flexible. We feel this is confusing as complex is often associated with difficult. KNN with \\(k = 1\\) is actually a very simple model, but it is very flexible.) Before moving to an example of tuning a KNN model, we will first introduce decision trees. 7.4 Decision Trees Decision trees are similar to k-nearest neighbors but instead of looking for neighbors, decision trees create neighborhoods. We won’t explore the full details of trees, but just start to understand the basic concepts, as well as learn to fit them in R. Neighborhoods are created via recursive binary partitions. In simpler terms, pick a feature and a possible cutoff value. Data that have a value less than the cutoff for the selected feature are in one neighborhood (the left) and data that have a value greater than the cutoff are in another (the right). Within these two neighborhoods, repeat this procedure until a stopping rule is satisfied. (More on that in a moment.) To make a prediction, check which neighborhood a new piece of data would belong to and predict the average of the \\(y_i\\) values of data in that neighborhood. With the data above, which has a single feature \\(x\\), consider three possible cutoffs: -0.5, 0.0, and 0.75. For each plot, the black vertical line defines the neighborhoods. The green horizontal lines are the average of the \\(y_i\\) values for the points in the left neighborhood. The red horizontal lines are the average of the \\(y_i\\) values for the points in the right neighborhood. What makes a cutoff good? Large differences in the average \\(y_i\\) between the two neighborhoods. More formally we want to find a cutoff value that minimizes \\[ \\sum_{i \\in N_L}(y_i - \\hat{\\mu}_{N_L}) ^ 2 + \\sum_{i \\in N_R}(y_i - \\hat{\\mu}_{N_R}) ^ 2 \\] where \\(N_L\\) are the data in the left neighborhood \\(\\hat{\\mu}_{N_L}\\) is the mean of the \\(y_i\\) for data in the left neighborhood Cutoff Total MSE Left MSE Right MSE -0.50 45.02 21.28 23.74 0.00 58.94 44.68 14.26 0.75 56.71 55.46 1.25 The table above summarizes the results of the three potential splits. We see that (of the splits considered, which are not exhaustive) the split based on a cutoff of \\(x = -0.50\\) creates the best partitioning of the space. Now let’s consider building a full tree. In the plot above, the true regression function is the dashed black curve, and the solid orange curve is the estimated regression function using a decision tree. We see that there are two splits, which we can visualize as a tree. The above “tree” shows the splits that were made. It informs us of the variable used, the cutoff value, and some summary of the resulting neighborhood. In “tree” terminology the resulting neighborhoods are “terminal nodes” of the tree. In contrast, “internal nodes” are neighborhoods that are created, but then further split. The “root node” or neighborhood before any splitting is at the top of the plot. We see that this node represents 100% of the data. The other number, 0.21, is the mean of the response variable, in this case, \\(y_i\\). Looking at a terminal node, for example the bottom left node, we see that 23% of the data is in this node. The average value of the \\(y_i\\) in this node is -1, which can be seen in the plot above. We also see that the first split is based on the \\(x\\) variable, and a cutoff of \\(x = -0.52\\). (Note that because there is only one variable here, all splits are based on \\(x\\), but in the future, we will have multiple features that can be split and neighborhoods will no longer be one-dimensional. However, this is hard to plot.) Let’s build a bigger, more flexible tree. There are two tuning parameters at play here which we will call by their names in R which we will see soon: cp or the “complexity parameter” as it is called. (Flexibility parameter would be a better name.) This parameter determines which splits are considered. A split must improve the performance of the tree by more than cp in order to be considered. When we get to R, we will see that the default value is 0.1. minsplit, the minimum number of observations in a node (neighborhood) in order to split again. There are actually many more possible tuning parameters for trees, possibly differing depending on who wrote the code you’re using. We will limit discussion to these two. Note that they effect each other, and they effect other parameters which we are not discussing. The main takeaway should be how they effect model flexibility. First let’s look at what happens for a fixed minsplit by variable cp. We see that as cp decreases, model flexibility increases. Now the reverse, fix cp and vary minsplit. We see that as minsplit decreases, model flexibility increases. 7.5 Example: Credit Card Data Let’s return to the credit card data from the previous chapter. While last time we used the data to inform a bit of analysis, this time we will simply use the dataset to illustrate some concepts. # load data, coerce to tibble crdt = as_tibble(ISLR::Credit) Again, we are using the Credit data form the ISLR package. Note: this is not real data. It has been simulated. # data prep crdt = crdt %&gt;% select(-ID) %&gt;% select(-Rating, everything()) We remove the ID variable as it should have no predictive power. We also move the Rating variable to the last column with a clever dplyr trick. This is in no way necessary, but is useful in creating some plots. # test-train split set.seed(1) crdt_trn_idx = sample(nrow(crdt), size = 0.8 * nrow(crdt)) crdt_trn = crdt[crdt_trn_idx, ] crdt_tst = crdt[-crdt_trn_idx, ] # estimation-validation split crdt_est_idx = sample(nrow(crdt_trn), size = 0.8 * nrow(crdt_trn)) crdt_est = crdt_trn[crdt_est_idx, ] crdt_val = crdt_trn[-crdt_est_idx, ] After train-test and estimation-validation splitting the data, we look at the train data. # check data head(crdt_trn, n = 10) ## # A tibble: 10 x 11 ## Income Limit Cards Age Education Gender Student Married Ethnicity Balance ## &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 183. 13913 4 98 17 &quot; Mal… No Yes Caucasian 1999 ## 2 35.7 2880 2 35 15 &quot; Mal… No No African … 0 ## 3 123. 8376 2 89 17 &quot; Mal… Yes No African … 1259 ## 4 20.8 2672 1 70 18 &quot;Fema… No No African … 0 ## 5 39.1 5565 4 48 18 &quot;Fema… No Yes Caucasian 772 ## 6 36.5 3806 2 52 13 &quot; Mal… No No African … 188 ## 7 45.1 3762 3 80 8 &quot; Mal… No Yes Caucasian 70 ## 8 43.5 2906 4 69 11 &quot; Mal… No No Caucasian 0 ## 9 23.1 3476 2 50 15 &quot;Fema… No No Caucasian 209 ## 10 53.2 4943 2 46 16 &quot;Fema… No Yes Asian 382 ## # … with 1 more variable: Rating &lt;int&gt; Recall that we would like to predict the Rating variable. This time, let’s try to use only demographic information as predictors. In particular, let’s focus on Age (numeric), Gender (categorical), and Student (categorical). Let’s fit KNN models with these features, and various values of \\(k\\). To do so, we use the knnreg() function from the caret package. (There are many other KNN functions in R. However, the operation and syntax of knnreg() better matches other functions we will use in this course.) Use ?knnreg for documentation and details. crdt_knn_01 = knnreg(Rating ~ Age + Gender + Student, data = crdt_est, k = 1) crdt_knn_10 = knnreg(Rating ~ Age + Gender + Student, data = crdt_est, k = 10) crdt_knn_25 = knnreg(Rating ~ Age + Gender + Student, data = crdt_est, k = 25) Here, we fit three models to the estimation data. We supply the variables that will be used as features as we would with lm(). We also specify how many neighbors to consider via the k argument. But wait a second, what is the distance from non-student to student? From male to female? In other words, how does KNN handle categorical variables? It doesn’t! Like lm() it creates dummy variables under the hood. Note: To this point, and until we specify otherwise, we will always coerce categorical variables to be factor variables in R. We will then let modeling functions such as lm() or knnreg() deal with the creation of dummy variables internally. head(crdt_knn_10$learn$X) ## Age GenderFemale StudentYes ## 1 30 0 0 ## 2 25 0 0 ## 3 44 0 0 ## 4 73 1 0 ## 5 44 0 1 ## 6 71 0 0 Once these dummy variables have been created, we have a numeric \\(X\\) matrix, which makes distance calculations easy. For example, the distance between the 4th and 5th observation here is 29.02. dist(head(crdt_knn_10$learn$X)) ## 1 2 3 4 5 ## 2 5.000000 ## 3 14.000000 19.000000 ## 4 43.011626 48.010416 29.017236 ## 5 14.035669 19.026298 1.000000 29.034462 ## 6 41.000000 46.000000 27.000000 2.236068 27.018512 sqrt(sum((crdt_knn_10$learn$X[4, ] - crdt_knn_10$learn$X[5, ]) ^ 2)) ## [1] 29.03446 (What about interactions? Basically, you’d have to create them the same way as you do for linear models. We only mention this to contrast with trees in a bit.) OK, so of these three models, which one performs best? (Where for now, “best” is obtaining the lowest validation RMSE.) First, note that we return to the predict() function as we did with lm(). predict(crdt_knn_10, crdt_val[1:5, ]) ## [1] 337.7857 356.0000 295.7692 360.8182 306.8000 This uses the 10-NN (10 nearest neighbors) model to make predictions (estimate the regression function) given the first five observations of the validation data. (Note: We did not name the second argument to predict(). Again, you’ve been warned.) Now that we know we already know how to use the predict() function, let’s calculate the validation RMSE for each of these models. knn_mod_list = list( crdt_knn_01 = knnreg(Rating ~ Age + Gender + Student, data = crdt_est, k = 1), crdt_knn_10 = knnreg(Rating ~ Age + Gender + Student, data = crdt_est, k = 10), crdt_knn_25 = knnreg(Rating ~ Age + Gender + Student, data = crdt_est, k = 25) ) knn_val_pred = map(knn_mod_list, predict, crdt_val) calc_rmse = function(actual, predicted) { sqrt(mean((actual - predicted) ^ 2)) } map_dbl(knn_val_pred, calc_rmse, crdt_val$Rating) ## crdt_knn_01 crdt_knn_10 crdt_knn_25 ## 182.3469 149.2172 138.6527 So, of these three values of \\(k\\), the model with \\(k = 25\\) achieves the lowest validation RMSE. This process, fitting a number of models with different values of the tuning parameter, in this case \\(k\\), and then finding the “best” tuning parameter value based on performance on the validation data is called tuning. In practice, we would likely consider more values of \\(k\\), but this should illustrate the point. In the next chapters, we will discuss the details of model flexibility and model tuning, and how these concepts are tied together. However, even though we will present some theory behind this relationship, in practice, you must tune and validate your models. There is no theory that will inform you ahead of tuning and validation which model will be the best. By teaching you how to fit KNN models in R and how to calculate validation RMSE, you already have all the tools you need to find a good model. Let’s turn to decision trees which we will fit with the rpart() function from the rpart package. Use ?rpart and ?rpart.control for documentation and details. We’ll start by using default tuning parameters. crdt_tree = rpart(Rating ~ Age + Gender + Student, data = crdt_est) crdt_tree ## n= 256 ## ## node), split, n, deviance, yval ## * denotes terminal node ## ## 1) root 256 6667400.0 357.0781 ## 2) Age&lt; 82.5 242 5865419.0 349.3719 ## 4) Age&gt;=69.5 52 1040678.0 313.0385 * ## 5) Age&lt; 69.5 190 4737307.0 359.3158 ## 10) Age&lt; 38.5 55 700013.2 326.6000 * ## 11) Age&gt;=38.5 135 3954443.0 372.6444 ## 22) Student=Yes 14 180764.4 297.7857 * ## 23) Student=No 121 3686148.0 381.3058 ## 46) Age&gt;=50.5 64 1881299.0 359.2344 ## 92) Age&lt; 53.5 9 48528.0 278.3333 * ## 93) Age&gt;=53.5 55 1764228.0 372.4727 * ## 47) Age&lt; 50.5 57 1738665.0 406.0877 * ## 3) Age&gt;=82.5 14 539190.9 490.2857 * Above we see the resulting tree printed, however, this is difficult to read. Instead, we use the rpart.plot() function from the rpart.plot package to better visualize the tree. rpart.plot(crdt_tree) At each split, the variable used to split is listed together with a condition. (If the condition is true for a data point, send it to the left neighborhood.) Although the Gender variable was used, we only see splits based on Age and Student. (This hints at the relative importance of these variables for prediction. More on this much later.) Categorical variables are split based on potential categories! This is excellent. This means that trees naturally handle categorical features without needing to convert to numeric under the hood. We see a split that puts students into one neighborhood, and non-students into another. Notice that the splits happen in order. So for example, the third terminal node (with an average rating of 298) is based on splits of: Age &lt; 83 Age &lt; 70 Age &gt; 39 Student = Yes In other words, individuals in this terminal node are students who are between the ages of 39 and 70. (Only 5% of the data is represented here.) This is basically an interaction between Age and Student without any need to directly specify it! What a great feature of trees. To recap: Trees do not make assumptions about the form of the regression function. Trees automatically handle categorical features. Trees naturally incorporate interaction. Now let’s fit another tree that is more flexible by relaxing some tuning parameters. (By default, cp = 0.1 and minsplit = 20.) crdt_tree_big = rpart(Rating ~ Age + Gender + Student, data = crdt_est, cp = 0.0, minsplit = 20) rpart.plot(crdt_tree_big) To make the tree even bigger, we could reduce minsplit, but in practice we mostly consider the cp parameter. (We will occasionally modify the minsplit parameter on quizzes.) Since minsplit has been kept the same, but cp was reduced, we see the same splits as the smaller tree, but many additional splits. Now let’s fit a bunch of trees, with different values of cp, for tuning. tree_mod_list = list( crdt_tree_0000 = rpart(Rating ~ Age + Gender + Student, data = crdt_est, cp = 0.000), crdt_tree_0001 = rpart(Rating ~ Age + Gender + Student, data = crdt_est, cp = 0.001), crdt_tree_0010 = rpart(Rating ~ Age + Gender + Student, data = crdt_est, cp = 0.010), crdt_tree_0100 = rpart(Rating ~ Age + Gender + Student, data = crdt_est, cp = 0.100) ) tree_val_pred = map(tree_mod_list, predict, crdt_val) map_dbl(tree_val_pred, calc_rmse, crdt_val$Rating) ## crdt_tree_0000 crdt_tree_0001 crdt_tree_0010 crdt_tree_0100 ## 156.3527 155.4262 151.9081 140.0806 Here we see the least flexible model, with cp = 0.100, performs best. Note that by only using these three features, we are severely limiting our models performance. Let’s quickly assess using all available predictors. crdt_tree_all = rpart(Rating ~ ., data = crdt_est) rpart.plot(crdt_tree_all) Notice that this model only splits based on Limit despite using all features. (This should be a big hint about which variables are useful for prediction.) calc_rmse( actual = crdt_val$Rating, predicted = predict(crdt_tree_all, crdt_val) ) ## [1] 28.8498 This model performs much better. You should try something similar with the KNN models above. Also, consider comparing this result to results from last chapter using linear models. Notice that we’ve been using that trusty predict() function here again. predict(crdt_tree_all, crdt_val[1:5, ]) ## 1 2 3 4 5 ## 292.8182 467.5152 467.5152 467.5152 772.4000 What does this code do? It estimates the mean Rating given the feature information (the “x” values) from the first five observations from the validation data using a decision tree model with default tuning parameters. Hopefully a theme is emerging. 7.6 Source R Markdown: 07-nonparametric-regression.Rmd "],
["biasvariance-tradeoff.html", "Chapter 8 Bias–Variance Tradeoff 8.1 Reducible and Irreducible Error 8.2 Bias-Variance Decomposition 8.3 Simulation 8.4 Estimating Expected Prediction Error 8.5 Source", " Chapter 8 Bias–Variance Tradeoff This chapter will begin to dig into some theoretical details of estimating the true regression function. Don’t fret if this presentation seems overwhelming. Next chapter we will review some general concepts about regression before moving on to classification. TODO: Proofread for technical and notational correctness. Consider the general regression setup where we are given a random pair \\((X, Y) \\in \\mathbb{R}^p \\times \\mathbb{R}\\). We would like to “predict” \\(Y\\) with some function of \\(X\\), say, \\(f(X)\\). To clarify what we mean by “predict,” we specify that we would like \\(f(X)\\) to be “close” to \\(Y\\). To further clarify what we mean by “close,” we define the squared error loss of estimating \\(Y\\) using \\(f(X)\\). \\[ L(Y, f(X)) \\triangleq (Y - f(X)) ^ 2 \\] Now we can clarify the goal of regression, which is to minimize the above loss, on average. We call this the risk of estimating \\(Y\\) using \\(f(X)\\). \\[ R(Y, f(X)) \\triangleq \\mathbb{E}[L(Y, f(X))] = \\mathbb{E}_{X, Y}[(Y - f(X)) ^ 2] \\] Before attempting to minimize the risk, we first re-write the risk after conditioning on \\(X\\). \\[ \\mathbb{E}_{X, Y} \\left[ (Y - f(X)) ^ 2 \\right] = \\mathbb{E}_{X} \\mathbb{E}_{Y \\mid X} \\left[ ( Y - f(X) ) ^ 2 \\mid X = x \\right] \\] Minimizing the right-hand side is much easier, as it simply amounts to minimizing the inner expectation with respect to \\(Y \\mid X\\), essentially minimizing the risk pointwise, for each \\(x\\). It turns out, that the risk is minimized by setting \\(f(x)\\) to be equal the conditional mean of \\(Y\\) given \\(X\\), \\[ f(x) = \\mathbb{E}(Y \\mid X = x) \\] which we call the regression function. (Note that in this chapter, we will refer to \\(f(x)\\) as the regression function instead of \\(\\mu(x)\\) for unimportant and arbitrary reasons.) Note that the choice of squared error loss is somewhat arbitrary. Suppose instead we chose absolute error loss. \\[ L(Y, f(X)) \\triangleq | Y - f(X) | \\] The risk would then be minimized setting \\(f(x)\\) equal to the conditional median. \\[ f(x) = \\text{median}(Y \\mid X = x) \\] Despite this possibility, our preference will still be for squared error loss. The reasons for this are numerous, including: historical, ease of optimization, and protecting against large deviations. Now, given data \\(\\mathcal{D} = (x_i, y_i) \\in \\mathbb{R}^p \\times \\mathbb{R}\\), our goal becomes finding some \\(\\hat{f}\\) that is a good estimate of the regression function \\(f\\). We’ll see that this amounts to minimizing what we call the reducible error. 8.1 Reducible and Irreducible Error Suppose that we obtain some \\(\\hat{f}\\), how well does it estimate \\(f\\)? We define the expected prediction error of predicting \\(Y\\) using \\(\\hat{f}(X)\\). A good \\(\\hat{f}\\) will have a low expected prediction error. \\[ \\text{EPE}\\left(Y, \\hat{f}(X)\\right) \\triangleq \\mathbb{E}_{X, Y, \\mathcal{D}} \\left[ \\left( Y - \\hat{f}(X) \\right)^2 \\right] \\] This expectation is over \\(X\\), \\(Y\\), and also \\(\\mathcal{D}\\). The estimate \\(\\hat{f}\\) is actually random depending on the sampled data \\(\\mathcal{D}\\). We could actually write \\(\\hat{f}(X, \\mathcal{D})\\) to make this dependence explicit, but our notation will become cumbersome enough as it is. Like before, we’ll condition on \\(X\\). This results in the expected prediction error of predicting \\(Y\\) using \\(\\hat{f}(X)\\) when \\(X = x\\). \\[ \\text{EPE}\\left(Y, \\hat{f}(x)\\right) = \\mathbb{E}_{Y \\mid X, \\mathcal{D}} \\left[ \\left(Y - \\hat{f}(X) \\right)^2 \\mid X = x \\right] = \\underbrace{\\mathbb{E}_{\\mathcal{D}} \\left[ \\left(f(x) - \\hat{f}(x) \\right)^2 \\right]}_\\textrm{reducible error} + \\underbrace{\\mathbb{V}_{Y \\mid X} \\left[ Y \\mid X = x \\right]}_\\textrm{irreducible error} \\] A number of things to note here: The expected prediction error is for a random \\(Y\\) given a fixed \\(x\\) and a random \\(\\hat{f}\\). As such, the expectation is over \\(Y \\mid X\\) and \\(\\mathcal{D}\\). Our estimated function \\(\\hat{f}\\) is random depending on the sampled data, \\(\\mathcal{D}\\), which is used to perform the estimation. The expected prediction error of predicting \\(Y\\) using \\(\\hat{f}(X)\\) when \\(X = x\\) has been decomposed into two errors: The reducible error, which is the expected squared error loss of estimation \\(f(x)\\) using \\(\\hat{f}(x)\\) at a fixed point \\(x\\). The only thing that is random here is \\(\\mathcal{D}\\), the data used to obtain \\(\\hat{f}\\). (Both \\(f\\) and \\(x\\) are fixed.) We’ll often call this reducible error the mean squared error of estimating \\(f(x)\\) using \\(\\hat{f}\\) at a fixed point \\(x\\). \\[ \\text{MSE}\\left(f(x), \\hat{f}(x)\\right) \\triangleq \\mathbb{E}_{\\mathcal{D}} \\left[ \\left(f(x) - \\hat{f}(x) \\right)^2 \\right]\\] The irreducible error. This is simply the variance of \\(Y\\) given that \\(X = x\\), essentially noise that we do not want to learn. This is also called the Bayes error. As the name suggests, the reducible error is the error that we have some control over. But how do we control this error? 8.2 Bias-Variance Decomposition After decomposing the expected prediction error into reducible and irreducible error, we can further decompose the reducible error. Recall the definition of the bias of an estimator. \\[ \\text{bias}(\\hat{\\theta}) \\triangleq \\mathbb{E}\\left[\\hat{\\theta}\\right] - \\theta \\] Also recall the definition of the variance of an estimator. \\[ \\mathbb{V}(\\hat{\\theta}) = \\text{var}(\\hat{\\theta}) \\triangleq \\mathbb{E}\\left [ ( \\hat{\\theta} -\\mathbb{E}\\left[\\hat{\\theta}\\right] )^2 \\right] \\] Using this, we further decompose the reducible error (mean squared error) into bias squared and variance. \\[ \\text{MSE}\\left(f(x), \\hat{f}(x)\\right) = \\mathbb{E}_{\\mathcal{D}} \\left[ \\left(f(x) - \\hat{f}(x) \\right)^2 \\right] = \\underbrace{\\left(f(x) - \\mathbb{E} \\left[ \\hat{f}(x) \\right] \\right)^2}_{\\text{bias}^2 \\left(\\hat{f}(x) \\right)} + \\underbrace{\\mathbb{E} \\left[ \\left( \\hat{f}(x) - \\mathbb{E} \\left[ \\hat{f}(x) \\right] \\right)^2 \\right]}_{\\text{var} \\left(\\hat{f}(x) \\right)} \\] This is actually a common fact in estimation theory, but we have stated it here specifically for estimation of some regression function \\(f\\) using \\(\\hat{f}\\) at some point \\(x\\). \\[ \\text{MSE}\\left(f(x), \\hat{f}(x)\\right) = \\text{bias}^2 \\left(\\hat{f}(x) \\right) + \\text{var} \\left(\\hat{f}(x) \\right) \\] In a perfect world, we would be able to find some \\(\\hat{f}\\) which is unbiased, that is \\(\\text{bias}\\left(\\hat{f}(x) \\right) = 0\\), which also has low variance. In practice, this isn’t always possible. It turns out, there is a bias-variance tradeoff. That is, often, the more bias in our estimation, the lesser the variance. Similarly, less variance is often accompanied by more bias. Complex models tend to be unbiased, but highly variable. Simple models are often extremely biased, but have low variance. In the context of regression, models are biased when: Parametric: The form of the model does not incorporate all the necessary variables, or the form of the relationship is too simple. For example, a parametric model assumes a linear relationship, but the true relationship is quadratic. Non-parametric: The model provides too much smoothing. In the context of regression, models are variable when: Parametric: The form of the model incorporates too many variables, or the form of the relationship is too complex. For example, a parametric model assumes a cubic relationship, but the true relationship is linear. Non-parametric: The model does not provide enough smoothing. It is very, “wiggly.” So for us, to select a model that appropriately balances the tradeoff between bias and variance, and thus minimizes the reducible error, we need to select a model of the appropriate complexity for the data. Recall that when fitting models, we’ve seen that train RMSE decreases as model complexity is increasing. (Technically it is non-increasing.) For test RMSE, we expect to see a U-shaped curve. Importantly, test RMSE decreases, until a certain complexity, then begins to increase. Now we can understand why this is happening. The expected test RMSE is essentially the expected prediction error, which we now known decomposes into (squared) bias, variance, and the irreducible Bayes error. The following plots show three examples of this. The three plots show three examples of the bias-variance tradeoff. In the left panel, the variance influences the expected prediction error more than the bias. In the right panel, the opposite is true. The middle panel is somewhat neutral. In all cases, the difference between the Bayes error (the horizontal dashed grey line) and the expected prediction error (the solid black curve) is exactly the mean squared error, which is the sum of the squared bias (blue curve) and variance (orange curve). The vertical line indicates the complexity that minimizes the prediction error. To summarize, if we assume that irreducible error can be written as \\[ \\mathbb{V}[Y \\mid X = x] = \\sigma ^ 2 \\] then we can write the full decomposition of the expected prediction error of predicting \\(Y\\) using \\(\\hat{f}\\) when \\(X = x\\) as \\[ \\text{EPE}\\left(Y, \\hat{f}(x)\\right) = \\underbrace{\\text{bias}^2\\left(\\hat{f}(x)\\right) + \\text{var}\\left(\\hat{f}(x)\\right)}_\\textrm{reducible error} + \\sigma^2. \\] As model complexity increases, bias decreases, while variance increases. By understanding the tradeoff between bias and variance, we can manipulate model complexity to find a model that well predict well on unseen observations. 8.3 Simulation We will illustrate these decompositions, most importantly the bias-variance tradeoff, through simulation. Suppose we would like to train a model to learn the true regression function function \\(f(x) = x^2\\). f = function(x) { x ^ 2 } More specifically, we’d like to predict an observation, \\(Y\\), given that \\(X = x\\) by using \\(\\hat{f}(x)\\) where \\[ \\mathbb{E}[Y \\mid X = x] = f(x) = x^2 \\] and \\[ \\mathbb{V}[Y \\mid X = x] = \\sigma ^ 2. \\] Alternatively, we could write this as \\[ Y = f(X) + \\epsilon \\] where \\(\\mathbb{E}[\\epsilon] = 0\\) and \\(\\mathbb{V}[\\epsilon] = \\sigma ^ 2\\). In this formulation, we call \\(f(X)\\) the signal and \\(\\epsilon\\) the noise. To carry out a concrete simulation example, we need to fully specify the data generating process. We do so with the following R code. gen_sim_data = function(f, sample_size = 100) { x = runif(n = sample_size, min = 0, max = 1) y = rnorm(n = sample_size, mean = f(x), sd = 0.3) data.frame(x, y) } Also note that if you prefer to think of this situation using the \\(Y = f(X) + \\epsilon\\) formulation, the following code represents the same data generating process. gen_sim_data = function(f, sample_size = 100) { x = runif(n = sample_size, min = 0, max = 1) eps = rnorm(n = sample_size, mean = 0, sd = 0.75) y = f(x) + eps data.frame(x, y) } To completely specify the data generating process, we have made more model assumptions than simply \\(\\mathbb{E}[Y \\mid X = x] = x^2\\) and \\(\\mathbb{V}[Y \\mid X = x] = \\sigma ^ 2\\). In particular, The \\(x_i\\) in \\(\\mathcal{D}\\) are sampled from a uniform distribution over \\([0, 1]\\). The \\(x_i\\) and \\(\\epsilon\\) are independent. The \\(y_i\\) in \\(\\mathcal{D}\\) are sampled from the conditional normal distribution. \\[ Y \\mid X \\sim N(f(x), \\sigma^2) \\] Using this setup, we will generate datasets, \\(\\mathcal{D}\\), with a sample size \\(n = 100\\) and fit four models. \\[ \\begin{aligned} \\texttt{predict(fit0, x)} &amp;= \\hat{f}_0(x) = \\hat{\\beta}_0\\\\ \\texttt{predict(fit1, x)} &amp;= \\hat{f}_1(x) = \\hat{\\beta}_0 + \\hat{\\beta}_1 x \\\\ \\texttt{predict(fit2, x)} &amp;= \\hat{f}_2(x) = \\hat{\\beta}_0 + \\hat{\\beta}_1 x + \\hat{\\beta}_2 x^2 \\\\ \\texttt{predict(fit9, x)} &amp;= \\hat{f}_9(x) = \\hat{\\beta}_0 + \\hat{\\beta}_1 x + \\hat{\\beta}_2 x^2 + \\ldots + \\hat{\\beta}_9 x^9 \\end{aligned} \\] To get a sense of the data and these four models, we generate one simulated dataset, and fit the four models. set.seed(1) sim_data = gen_sim_data(f) fit_0 = lm(y ~ 1, data = sim_data) fit_1 = lm(y ~ poly(x, degree = 1), data = sim_data) fit_2 = lm(y ~ poly(x, degree = 2), data = sim_data) fit_9 = lm(y ~ poly(x, degree = 9), data = sim_data) Note that technically we’re being lazy and using orthogonal polynomials, but the fitted values are the same, so this makes no difference for our purposes. Plotting these four trained models, we see that the zero predictor model does very poorly. The first degree model is reasonable, but we can see that the second degree model fits much better. The ninth degree model seem rather wild. The following three plots were created using three additional simulated datasets. The zero predictor and ninth degree polynomial were fit to each. This plot should make clear the difference between the bias and variance of these two models. The zero predictor model is clearly wrong, that is, biased, but nearly the same for each of the datasets, since it has very low variance. While the ninth degree model doesn’t appear to be correct for any of these three simulations, we’ll see that on average it is, and thus is performing unbiased estimation. These plots do however clearly illustrate that the ninth degree polynomial is extremely variable. Each dataset results in a very different fitted model. Correct on average isn’t the only goal we’re after, since in practice, we’ll only have a single dataset. This is why we’d also like our models to exhibit low variance. We could have also fit \\(k\\)-nearest neighbors models to these three datasets. Here we see that when \\(k = 100\\) we have a biased model with very low variance. (It’s actually the same as the 0 predictor linear model.) When \\(k = 5\\), we again have a highly variable model. These two sets of plots reinforce our intuition about the bias-variance tradeoff. Complex models (ninth degree polynomial and \\(k\\) = 5) are highly variable, and often unbiased. Simple models (zero predictor linear model and \\(k = 100\\)) are very biased, but have extremely low variance. We will now complete a simulation study to understand the relationship between the bias, variance, and mean squared error for the estimates for \\(f(x)\\) given by these four models at the point \\(x = 0.90\\). We use simulation to complete this task, as performing the analytical calculations would prove to be rather tedious and difficult. set.seed(1) n_sims = 250 n_models = 4 x = data.frame(x = 0.90) # fixed point at which we make predictions predictions = matrix(0, nrow = n_sims, ncol = n_models) for (sim in 1:n_sims) { # simulate new, random, training data # this is the only random portion of the bias, var, and mse calculations # this allows us to calculate the expectation over D sim_data = gen_sim_data(f) # fit models fit_0 = lm(y ~ 1, data = sim_data) fit_1 = lm(y ~ poly(x, degree = 1), data = sim_data) fit_2 = lm(y ~ poly(x, degree = 2), data = sim_data) fit_9 = lm(y ~ poly(x, degree = 9), data = sim_data) # get predictions predictions[sim, 1] = predict(fit_0, x) predictions[sim, 2] = predict(fit_1, x) predictions[sim, 3] = predict(fit_2, x) predictions[sim, 4] = predict(fit_9, x) } Note that this is one of many ways we could have accomplished this task using R. For example we could have used a combination of replicate() and *apply() functions. Alternatively, we could have used a tidyverse approach, which likely would have used some combination of dplyr, tidyr, and purrr. Our approach, which would be considered a base R approach, was chosen to make it as clear as possible what is being done. The tidyverse approach is rapidly gaining popularity in the R community, but might make it more difficult to see what is happening here, unless you are already familiar with that approach. Also of note, while it may seem like the output stored in predictions would meet the definition of tidy data given by Hadley Wickham since each row represents a simulation, it actually falls slightly short. For our data to be tidy, a row should store the simulation number, the model, and the resulting prediction. We’ve actually already aggregated one level above this. Our observational unit is a simulation (with four predictions), but for tidy data, it should be a single prediction. This may be revised by the author later when there are more examples of how to do this from the R community. The above plot shows the predictions for each of the 250 simulations of each of the four models of different polynomial degrees. The truth, \\(f(x = 0.90) = (0.9)^2 = 0.81\\), is given by the solid black horizontal line. Two things are immediately clear: As complexity increases, bias decreases. (The mean of a model’s predictions is closer to the truth.) As complexity increases, variance increases. (The variance about the mean of a model’s predictions increases.) The goal of this simulation study is to show that the following holds true for each of the four models. \\[ \\text{MSE}\\left(f(0.90), \\hat{f}_k(0.90)\\right) = \\underbrace{\\left(\\mathbb{E} \\left[ \\hat{f}_k(0.90) \\right] - f(0.90) \\right)^2}_{\\text{bias}^2 \\left(\\hat{f}_k(0.90) \\right)} + \\underbrace{\\mathbb{E} \\left[ \\left( \\hat{f}_k(0.90) - \\mathbb{E} \\left[ \\hat{f}_k(0.90) \\right] \\right)^2 \\right]}_{\\text{var} \\left(\\hat{f}_k(0.90) \\right)} \\] We’ll use the empirical results of our simulations to estimate these quantities. (Yes, we’re using estimation to justify facts about estimation.) Note that we’ve actually used a rather small number of simulations. In practice we should use more, but for the sake of computation time, we’ve performed just enough simulations to obtain the desired results. (Since we’re estimating estimation, the bigger the sample size, the better.) To estimate the mean squared error of our predictions, we’ll use \\[ \\widehat{\\text{MSE}}\\left(f(0.90), \\hat{f}_k(0.90)\\right) = \\frac{1}{n_{\\texttt{sims}}}\\sum_{i = 1}^{n_{\\texttt{sims}}} \\left(f(0.90) - \\hat{f}_k^{[i]}(0.90) \\right)^2 \\] where \\(\\hat{f}_k^{[i]}(0.90)\\) is the estimate of \\(f(0.90)\\) using the \\(i\\)-th from the polynomial degree \\(k\\) model. We also write an accompanying R function. get_mse = function(truth, estimate) { mean((estimate - truth) ^ 2) } Similarly, for the bias of our predictions we use, \\[ \\widehat{\\text{bias}} \\left(\\hat{f}(0.90) \\right) = \\frac{1}{n_{\\texttt{sims}}}\\sum_{i = 1}^{n_{\\texttt{sims}}} \\left(\\hat{f}_k^{[i]}(0.90) \\right) - f(0.90) \\] And again, we write an accompanying R function. get_bias = function(estimate, truth) { mean(estimate) - truth } Lastly, for the variance of our predictions we have \\[ \\widehat{\\text{var}} \\left(\\hat{f}(0.90) \\right) = \\frac{1}{n_{\\texttt{sims}}}\\sum_{i = 1}^{n_{\\texttt{sims}}} \\left(\\hat{f}_k^{[i]}(0.90) - \\frac{1}{n_{\\texttt{sims}}}\\sum_{i = 1}^{n_{\\texttt{sims}}}\\hat{f}_k^{[i]}(0.90) \\right)^2 \\] While there is already R function for variance, the following is more appropriate in this situation. get_var = function(estimate) { mean((estimate - mean(estimate)) ^ 2) } To quickly obtain these results for each of the four models, we utilize the apply() function. bias = apply(predictions, 2, get_bias, truth = f(x = 0.90)) variance = apply(predictions, 2, get_var) mse = apply(predictions, 2, get_mse, truth = f(x = 0.90)) We summarize these results in the following table. Degree Mean Squared Error Bias Squared Variance 0 0.22643 0.22476 0.00167 1 0.00829 0.00508 0.00322 2 0.00387 0.00005 0.00381 9 0.01019 0.00002 0.01017 A number of things to notice here: We use squared bias in this table. Since bias can be positive or negative, squared bias is more useful for observing the trend as complexity increases. The squared bias trend which we see here is decreasing as complexity increases, which we expect to see in general. The exact opposite is true of variance. As model complexity increases, variance increases. The mean squared error, which is a function of the bias and variance, decreases, then increases. This is a result of the bias-variance tradeoff. We can decrease bias, by increasing variance. Or, we can decrease variance by increasing bias. By striking the correct balance, we can find a good mean squared error! We can check for these trends with the diff() function in R. all(diff(bias ^ 2) &lt; 0) ## [1] TRUE all(diff(variance) &gt; 0) ## [1] TRUE diff(mse) &lt; 0 ## 1 2 9 ## TRUE TRUE FALSE The models with polynomial degrees 2 and 9 are both essentially unbiased. We see some bias here as a result of using simulation. If we increased the number of simulations, we would see both biases go down. Since they are both unbiased, the model with degree 2 outperforms the model with degree 9 due to its smaller variance. Models with degree 0 and 1 are biased because they assume the wrong form of the regression function. While the degree 9 model does this as well, it does include all the necessary polynomial degrees. \\[ \\hat{f}_9(x) = \\hat{\\beta}_0 + \\hat{\\beta}_1 x + \\hat{\\beta}_2 x^2 + \\ldots + \\hat{\\beta}_9 x^9 \\] Then, since least squares estimation is unbiased, importantly, \\[ \\mathbb{E}\\left[\\hat{\\beta}_d\\right] = \\beta_d = 0 \\] for \\(d = 3, 4, \\ldots 9\\), we have \\[ \\mathbb{E}\\left[\\hat{f}_9(x)\\right] = \\beta_0 + \\beta_1 x + \\beta_2 x^2 \\] Now we can finally verify the bias-variance decomposition. bias ^ 2 + variance == mse ## 0 1 2 9 ## FALSE FALSE FALSE TRUE But wait, this says it isn’t true, except for the degree 9 model? It turns out, this is simply a computational issue. If we allow for some very small error tolerance, we see that the bias-variance decomposition is indeed true for predictions from these for models. all.equal(bias ^ 2 + variance, mse) ## [1] TRUE See ?all.equal() for details. So far, we’ve focused our efforts on looking at the mean squared error of estimating \\(f(0.90)\\) using \\(\\hat{f}(0.90)\\). We could also look at the expected prediction error of using \\(\\hat{f}(X)\\) when \\(X = 0.90\\) to estimate \\(Y\\). \\[ \\text{EPE}\\left(Y, \\hat{f}_k(0.90)\\right) = \\mathbb{E}_{Y \\mid X, \\mathcal{D}} \\left[ \\left(Y - \\hat{f}_k(X) \\right)^2 \\mid X = 0.90 \\right] \\] We can estimate this quantity for each of the four models using the simulation study we already performed. get_epe = function(realized, estimate) { mean((realized - estimate) ^ 2) } y = rnorm(n = nrow(predictions), mean = f(x = 0.9), sd = 0.3) epe = apply(predictions, 2, get_epe, realized = y) epe ## 0 1 2 9 ## 0.3180470 0.1104055 0.1095955 0.1205570 What about the unconditional expected prediction error. That is, for any \\(X\\), not just \\(0.90\\). Specifically, the expected prediction error of estimating \\(Y\\) using \\(\\hat{f}(X)\\). The following (new) simulation study provides an estimate of \\[ \\text{EPE}\\left(Y, \\hat{f}_k(X)\\right) = \\mathbb{E}_{X, Y, \\mathcal{D}} \\left[ \\left( Y - \\hat{f}_k(X) \\right)^2 \\right] \\] for the quadratic model, that is \\(k = 2\\) as we have defined \\(k\\). set.seed(1) n_sims = 1000 X = runif(n = n_sims, min = 0, max = 1) Y = rnorm(n = n_sims, mean = f(X), sd = 0.3) f_hat_X = rep(0, length(X)) for (i in seq_along(X)) { sim_data = gen_sim_data(f) fit_2 = lm(y ~ poly(x, degree = 2), data = sim_data) f_hat_X[i] = predict(fit_2, newdata = data.frame(x = X[i])) } mean((Y - f_hat_X) ^ 2) ## [1] 0.09997319 Note that in practice, we should use many more simulations in this study. 8.4 Estimating Expected Prediction Error While previously, we only decomposed the expected prediction error conditionally, a similar argument holds unconditionally. Assuming \\[ \\mathbb{V}[Y \\mid X = x] = \\sigma ^ 2. \\] we have \\[ \\text{EPE}\\left(Y, \\hat{f}(X)\\right) = \\mathbb{E}_{X, Y, \\mathcal{D}} \\left[ (Y - \\hat{f}(X))^2 \\right] = \\underbrace{\\mathbb{E}_{X} \\left[\\text{bias}^2\\left(\\hat{f}(X)\\right)\\right] + \\mathbb{E}_{X} \\left[\\text{var}\\left(\\hat{f}(X)\\right)\\right]}_\\textrm{reducible error} + \\sigma^2 \\] Lastly, we note that if \\[ \\mathcal{D} = \\mathcal{D}_{\\texttt{trn}} \\cup \\mathcal{D}_{\\texttt{tst}} = (x_i, y_i) \\in \\mathbb{R}^p \\times \\mathbb{R}, \\ i = 1, 2, \\ldots n \\] where \\[ \\mathcal{D}_{\\texttt{trn}} = (x_i, y_i) \\in \\mathbb{R}^p \\times \\mathbb{R}, \\ i \\in \\texttt{trn} \\] and \\[ \\mathcal{D}_{\\texttt{tst}} = (x_i, y_i) \\in \\mathbb{R}^p \\times \\mathbb{R}, \\ i \\in \\texttt{tst} \\] Then, if we use \\(\\mathcal{D}_{\\texttt{trn}}\\) to fit (train) a model, we can use the test mean squared error \\[ \\sum_{i \\in \\texttt{tst}}\\left(y_i - \\hat{f}(x_i)\\right) ^ 2 \\] as an estimate of \\[ \\mathbb{E}_{X, Y, \\mathcal{D}} \\left[ (Y - \\hat{f}(X))^2 \\right] \\] the expected prediction error. (In practice we prefer RMSE to MSE for comparing models and reporting because of the units.) How good is this estimate? Well, if \\(\\mathcal{D}\\) is a random sample from \\((X, Y)\\), and \\(\\texttt{tst}\\) are randomly sampled observations randomly sampled from \\(i = 1, 2, \\ldots, n\\), then it is a reasonable estimate. However, it is rather variable due to the randomness of selecting the observations for the test set. How variable? It turns out, pretty variable. While it’s a justified estimate, eventually we’ll introduce cross-validation as a procedure better suited to performing this estimation to select a model. 8.5 Source R Markdown: 08-bvt.Rmd "],
["regression-overview.html", "Chapter 9 Regression Overview 9.1 Goal 9.2 Strategy 9.3 Models 9.4 Model Flexibility 9.5 Overfitting 9.6 Bias-Variance Tradeoff 9.7 Source", " Chapter 9 Regression Overview This chapter will provide an overview of the regression concepts that we have learned thus far. It will also serve to outline the general concepts of supervised learning which will also apply to our next task, classification. The information here may eventually be merged into the previous chapter, but for now it is separated for clarify. (Also, much of this information already appears there.) 9.1 Goal What is the goal of regression models in the context of machine learning? We can discuss it in two ways: Make predictions on unseen data. Estimate the regression function, which under squared error loss is the conditional mean of \\(Y\\), the response, given \\(X\\), the features. These goal are essentially the same. We want to fit a model that “generalizes” well, that is, works well on unseen data. To do this, we want to use a model of appropriate flexibility so as not to overfit to the train data. In other words, we want to train a models that learns the signal, the regression function, and not the noise, the random variation in the training data. In previous chapters we have formalized this goal a bit more mathematically, but for a general recap, we stick to more casual language. 9.2 Strategy How do we find and train models that generalize well to unseen data? We generally follow these steps. Split the data in to training data and testing data. Within the training data, we will do whatever we would. The testing data will never be used to make any decision that lead to the selection of a model. We often use 80% of the available data for training. Split the training data into estimation data and validation data. We often use 80% of the available data for estimation. Decide on a set of candidate models. Fit (train) each candidate model to the estimation data. Evaluate all candidate models fit to the estimation data based on their performance on the validation data. Performance here is based on the ability of the model to predict on the validation data which was not used to train the models. Select one of the candidate models based on the validation performance. Fit the chosen model to the entire training dataset. Estimate model performance using the test data. Note that we are using the validation data to select a model, while the test data is used to estimate model performance. 9.3 Models While there are many, many models that can be used for regression, we have focused on three families of models. We saw how each can be used to estimate the regression function. Importantly, each model family can be made more or less flexible to accommodate different datasets in order to find a model that predicts well. 9.3.0.1 Linear Models Linear models are a family of parametric models which assume that the regression function is a linear combination of the features. For example, with a single feature \\(x\\), we could assume \\[ \\mu(x) = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\beta_3 x^3 + \\ldots + \\beta_9 x^9 \\] Here, the \\(\\beta\\) coefficients are model parameters that are learned from the data via least squares or maximum likelihood. (Additionally, we could assume a conditional normal distribution with a constant variance, which would require estimating the \\(\\sigma\\) parameters. This is not necessary to estimate the mean.) 9.3.0.2 k-Nearest Neighbors k-Nearest Neighbors models are a family of nonparametric models with a single tuning parameter, \\(k\\), the number of neighbors to use when estimating the regression function. We can also control which features are used when measuring distances. 9.3.0.3 Decision Trees Decision Tree models are a family of nonparametric models with a number of tuning parameters, but most notably, cp, the “complexity parameter” which indirectly controls the number of splits used to create neighborhoods of observations. We can also control which features are used when considering splits. 9.4 Model Flexibility While we may not have explicitly stated this relationship, the plot below shows how train and validation “error” change as a function of model flexibility. The “error” in this plot could be any reasonable error metric used, for example, RMSE. While here we are specifically discussing estimation and validation error, we more generally are discussing an error metric calculated on the same data used to train the model (estimation) and an error metric calculated on data not used to train the model, for example the validation data. The “line” and “curve” seen above are highly idealized, that is, you won’t see nice linear and quadratic trends in practice. However, you will see that training error decreases as model flexibility increases. (This is essentially one of the few use cases for actually calculating training error, to verify this relationship as a sanity check.) On the other hand, often we will see that validation error first decreases, then increases as model flexibility increases. (Sometimes you might see only an increase or decrease which would suggest you need to also try additional models with more or less flexibility.) While the validation “curve” is idealized as a “curve” that decrease then increases, in practice, it might be a bit more “wiggly” just due to the random nature of the validation split. How can we modify the flexibility of the models we have considered? 9.4.0.1 Linear Models To increase the flexibility of linear models, add additional transformed features or simply add features. For example a model that assumes a quadratic mean function \\[ \\mu_1(x) = \\beta_0 + \\beta_1 x + \\beta_2 x ^ 2 \\] is more flexible than a model that assumes a linear mean function \\[ \\mu_2(x) = \\beta_0 + \\beta_1 x \\] The model that assumes a quadratic mean function can learn a linear mean function, but this added flexibility comes with a price. (Possible overfitting.) Similarly, a model that assumes the mean function is a function of two features \\[ \\mu_1(x) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 \\] is more flexible than a model that assumes the mean function is only a function of one of these features. \\[ \\mu_2(x) = \\beta_0 + \\beta_1 x \\] 9.4.0.2 k-Nearest Neighbors Given a set of feature variables, as \\(k\\) increases, model flexibility decreases. (Note that adding and removing features does have an effect on model flexibility, generally adding flexibility with additional features, there are situations where adding features will decrease training error.) 9.4.0.3 Decision Given a set of feature variables, as cp increases, model flexibility decreases. (Note that adding and removing features does have an effect on model flexibility, generally adding flexibility with additional features, there are situations where adding features will decrease training error.) 9.5 Overfitting Overfitting occurs when we have fit to not just the signal but also the noise. That is, a model performs too well on the training data. Let’s take a look at this visually. In each of the plots above, the dashed black curve represents the true mean function of interest, in this case, \\[ \\mu(x) = \\sin(x) \\] with points simulated about this mean according to a standard normal. (That is, the noise is standard normal.) We see that the model with \\(k = 1\\) has fit far too well to the training data. The estimated mean function, seen in green, goes through each training point. That is, there is no training error. This model is too flexible and is overfitting. We have learned both the signal and the noise, thus this model will predict poorly on new data. The model with \\(k = 25\\) has fits the training data poorly. The estimated mean function, seen in red, does not match the true mean function well. The points are far from the estimated mean function. his model is too inflexible and is underfitting. It has learned neither the signal not the noise. The model with \\(k = 5\\) seems like a reasonable in-between. Doesn’t seem to be chasing noise. Seems to reasonably approximate the true mean function. How do we assess over and underfitting in practice, when we don’t know the true mean function? We have to look at train and validation errors. Model that are probably underfitting: “Large” Train RMSE and a Validation RMSE larger than the smallest. The less flexible, the more probable the underfitting. Model that are probably overfitting: “Small” Train RMSE and a Validation RMSE larger than the smallest. The more flexible, the more probable the overfitting. The further a model is to the left of this plot, the greater the chance it is underfit. The further a model is to the right of this plot, the greater the chance it is overfit. 9.6 Bias-Variance Tradeoff Why does changing the model flexibility influence the predictive performance of these models? The bias-variance tradeoff. As models increase in flexibility, bias is decreased variance is increased And together, the MSE is equal to the bias squared plus the variance. However, the rate at which the variance increases can be and generally is different than the rate at which the bias deceases. This is why we must validate our models. Essentially, by modifying the model complexity and validating the results, we are trying to find the right balance between bias and variance. 9.7 Source R Markdown: 09-regression-overview.Rmd "],
["the-backlog.html", "A The Backlog A.1 Sorted A.2 Unsorted A.3 Source", " A The Backlog The backlog will contain a list of topics of discussion that have arisen during the semester that we will return to if there is time. A.1 Sorted Why are we so darn focused on means? https://www.benkuhn.net/squared https://news.ycombinator.com/item?id=9556459 A.2 Unsorted https://atrebas.github.io/post/2019-01-15-2018-learning/ Don’t load previous worksapce. (Screenshot of this option in RStudio.) How do we make prediction intervals? What is quantile regression? How do we detect and deal with outliers? In response versus features? At train time versus test time? A.3 Source R Markdown: 98-backlog.Rmd "]
]
